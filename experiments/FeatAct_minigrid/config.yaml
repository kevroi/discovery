env_name: 'MiniGrid-DoorKey-5x5-v0'
learner: 'PPO'
project_name: 'testing_feature_logging'
timesteps: 10000
policy_type: 'CnnPolicy'
cnn: 'minigrid'
activation: 'lrelu'
feat_dim: 128
record_video: False

# Shared hypers
lr: 0.0002 # PPO_def: 3e-4
gamma: 0.99 # PPO_def: 0.99
batch_size: 96 # PPO_def: 64, DQN_def: 32

# PPO hypers & SB3 defaults
n_epochs: 4 # 10
n_steps: 128 # 2048
n_envs: 16 # 1 #TODO this affects DDQN too!

# (D)DQN hypers & SB3 defaults
learning_starts: 1000 # 100
train_freq: 1 # 4
exploration_final_eps: 0.1 # 0.05
target_update_interval: 500 # 10000

# Env specific hypers
random_hallway: False # TwoRoomEnv