{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.11)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import torch\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from discovery.utils.feat_extractors import NatureCNN\n",
    "from stable_baselines3.common.utils import obs_as_tensor\n",
    "from discovery.experiments.FeatAct_minigrid.helpers import pre_process_obs\n",
    "import cv2\n",
    "\n",
    "from discovery.utils import filesys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to /Users/kevinroice/Documents/research/discovery\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinroice/Documents/research/discovery/venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at most 16 arguments, got 18\n",
      "  warnings.warn(\n",
      "/Users/kevinroice/Documents/research/discovery/venv/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: code expected at most 16 arguments, got 18\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "filesys.set_directory_in_project()\n",
    "agent = PPO.load(\"discovery/experiments/FeatAct_atari/models/Seaquest-v5_mpqgvvr1.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the seaquest dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = f\"/Users/kevinroice/Documents/research/discovery/datasets/AAD/clean/SeaquestNoFrameskip-v4/episode(1).hdf5\"\n",
    "with h5py.File(path, \"r\") as f:\n",
    "    state = f[\"state\"][...]\n",
    "labels = np.load(\"/Users/kevinroice/Documents/research/discovery/datasets/AAD/clean/SeaquestNoFrameskip-v4/episode(1)_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state[0, :, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_atari(dataset: np.ndarray):\n",
    "    num_images = dataset.shape[0]\n",
    "    preprocessed_images = np.zeros((num_images, 84, 84), dtype=np.uint8)\n",
    "\n",
    "    for i in range(num_images):\n",
    "        preprocessed_images[i] = cv2.resize(cv2.cvtColor(dataset[i], cv2.COLOR_RGB2GRAY), (84, 84))\n",
    "\n",
    "        # Stack frames\n",
    "        stacked_images = np.zeros((num_images - 3, 4, 84, 84), dtype=np.uint8)\n",
    "        for i in range(num_images - 3):\n",
    "            stacked_images[i] = np.stack(\n",
    "                [\n",
    "                    preprocessed_images[i],\n",
    "                    preprocessed_images[i + 1],\n",
    "                    preprocessed_images[i + 2],\n",
    "                    preprocessed_images[i + 3],\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return stacked_images\n",
    "\n",
    "\n",
    "def stack_labels(labels):\n",
    "    stacked_labels = np.zeros((labels.shape[0] - 3, 1), dtype=np.uint8)\n",
    "    for i in range(labels.shape[0] - 3):\n",
    "        stacked_labels[i] = labels[i + 3]\n",
    "    return np.squeeze(stacked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_to_feats_atari(model, preprocs):\n",
    "    with torch.no_grad():\n",
    "        tensors = obs_as_tensor(preprocs, model.device)\n",
    "        print(tensors.shape)\n",
    "        feats = model.policy.extract_features(tensors) \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_states = pre_process_atari(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn all 1s and 3s into 0s\n",
    "labels[labels == 1] = 0\n",
    "labels[labels == 3] = 0\n",
    "# turn all 2s into 1s\n",
    "labels[labels == 2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_labels = stack_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1354, 4, 84, 84)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1354,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1354, 4, 84, 84])\n"
     ]
    }
   ],
   "source": [
    "feats = preproc_to_feats_atari(agent, pre_processed_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from discovery.utils import sg_detection \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy\n",
    "import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import importlib\n",
    "\n",
    "def train_classifier(clf, X, labels,\n",
    "                     n_epochs=500,\n",
    "                     batch_size=32,\n",
    "                     test_size=0.2, random_state=0):\n",
    "    # X = torch.cat(feats, dim=0)\n",
    "    y = torch.tensor(labels).float()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=test_size,\n",
    "                                                        random_state=random_state)\n",
    "    \n",
    "    best_acc = - np.inf\n",
    "    best_weights = None\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size) # TODO: check if the last batch is included\n",
    "    loss_fn = nn.BCELoss(reduction='none')  # reduction='none' to get per-sample loss, not mean\n",
    "\n",
    "    num_pos = y_train.sum()\n",
    "    num_neg = len(y_train) - num_pos\n",
    "    base_weight = torch.tensor([1.0, num_neg/num_pos]) # for weighted mean in loss calculation\n",
    "    \n",
    "    optimizer = optim.Adam(clf.parameters(), lr=0.0001)\n",
    "    # TODO: collect positive examples, and concatenate them to each batch\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        clf.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=False) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = clf(X_batch)\n",
    "                y_batch = y_batch.unsqueeze(1)\n",
    "                weight = torch.where(y_batch == 1, base_weight[1], base_weight[0])\n",
    "                loss2 = loss_fn(y_pred, y_batch)\n",
    "                final_loss = torch.mean(weight*loss2)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                final_loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(final_loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # # evaluate accuracy at end of each epoch\n",
    "        # clf.eval()\n",
    "        # y_pred = clf(X_test)\n",
    "        # acc = (y_pred.round() == y_test).float().mean()\n",
    "        # acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(clf.state_dict())\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 34/34 [00:00<00:00, 177.88batch/s, acc=0.815, loss=0.519]\n",
      "Epoch 1: 100%|██████████| 34/34 [00:00<00:00, 319.82batch/s, acc=0.815, loss=0.552]\n",
      "Epoch 2: 100%|██████████| 34/34 [00:00<00:00, 314.19batch/s, acc=0.815, loss=0.538]\n",
      "Epoch 3: 100%|██████████| 34/34 [00:00<00:00, 310.84batch/s, acc=0.852, loss=0.501]\n",
      "Epoch 4: 100%|██████████| 34/34 [00:00<00:00, 299.15batch/s, acc=0.889, loss=0.458]\n",
      "Epoch 5: 100%|██████████| 34/34 [00:00<00:00, 282.95batch/s, acc=0.889, loss=0.419]\n",
      "Epoch 6: 100%|██████████| 34/34 [00:00<00:00, 286.41batch/s, acc=0.889, loss=0.384]\n",
      "Epoch 7: 100%|██████████| 34/34 [00:00<00:00, 218.26batch/s, acc=0.889, loss=0.355]\n",
      "Epoch 8: 100%|██████████| 34/34 [00:00<00:00, 202.58batch/s, acc=0.889, loss=0.331]\n",
      "Epoch 9: 100%|██████████| 34/34 [00:00<00:00, 285.27batch/s, acc=0.889, loss=0.311]\n",
      "Epoch 10: 100%|██████████| 34/34 [00:00<00:00, 280.37batch/s, acc=0.889, loss=0.295]\n",
      "Epoch 11: 100%|██████████| 34/34 [00:00<00:00, 276.38batch/s, acc=0.926, loss=0.281]\n",
      "Epoch 12: 100%|██████████| 34/34 [00:00<00:00, 285.78batch/s, acc=0.926, loss=0.27] \n",
      "Epoch 13: 100%|██████████| 34/34 [00:00<00:00, 283.43batch/s, acc=0.926, loss=0.26] \n",
      "Epoch 14: 100%|██████████| 34/34 [00:00<00:00, 300.51batch/s, acc=0.926, loss=0.252]\n",
      "Epoch 15: 100%|██████████| 34/34 [00:00<00:00, 132.55batch/s, acc=0.926, loss=0.245]\n",
      "Epoch 16: 100%|██████████| 34/34 [00:00<00:00, 231.61batch/s, acc=0.926, loss=0.24] \n",
      "Epoch 17: 100%|██████████| 34/34 [00:00<00:00, 135.35batch/s, acc=0.926, loss=0.235]\n",
      "Epoch 18: 100%|██████████| 34/34 [00:00<00:00, 205.12batch/s, acc=0.926, loss=0.231]\n",
      "Epoch 19: 100%|██████████| 34/34 [00:00<00:00, 208.44batch/s, acc=0.926, loss=0.227]\n",
      "Epoch 20: 100%|██████████| 34/34 [00:00<00:00, 283.24batch/s, acc=0.926, loss=0.224]\n",
      "Epoch 21: 100%|██████████| 34/34 [00:00<00:00, 226.51batch/s, acc=0.926, loss=0.221]\n",
      "Epoch 22: 100%|██████████| 34/34 [00:00<00:00, 210.12batch/s, acc=0.926, loss=0.218]\n",
      "Epoch 23: 100%|██████████| 34/34 [00:00<00:00, 236.88batch/s, acc=0.926, loss=0.215]\n",
      "Epoch 24: 100%|██████████| 34/34 [00:00<00:00, 268.99batch/s, acc=0.926, loss=0.213]\n",
      "Epoch 25: 100%|██████████| 34/34 [00:00<00:00, 276.62batch/s, acc=0.926, loss=0.211]\n",
      "Epoch 26: 100%|██████████| 34/34 [00:00<00:00, 281.23batch/s, acc=0.926, loss=0.209]\n",
      "Epoch 27: 100%|██████████| 34/34 [00:00<00:00, 289.89batch/s, acc=0.926, loss=0.207]\n",
      "Epoch 28: 100%|██████████| 34/34 [00:00<00:00, 145.21batch/s, acc=0.926, loss=0.205]\n",
      "Epoch 29: 100%|██████████| 34/34 [00:00<00:00, 131.33batch/s, acc=0.926, loss=0.203]\n",
      "Epoch 30: 100%|██████████| 34/34 [00:00<00:00, 228.71batch/s, acc=0.926, loss=0.202]\n",
      "Epoch 31: 100%|██████████| 34/34 [00:00<00:00, 188.79batch/s, acc=0.926, loss=0.2]  \n",
      "Epoch 32: 100%|██████████| 34/34 [00:00<00:00, 231.71batch/s, acc=0.926, loss=0.198]\n",
      "Epoch 33: 100%|██████████| 34/34 [00:00<00:00, 274.37batch/s, acc=0.926, loss=0.197]\n",
      "Epoch 34: 100%|██████████| 34/34 [00:00<00:00, 280.78batch/s, acc=0.926, loss=0.195]\n",
      "Epoch 35: 100%|██████████| 34/34 [00:00<00:00, 273.57batch/s, acc=0.926, loss=0.194]\n",
      "Epoch 36: 100%|██████████| 34/34 [00:00<00:00, 252.36batch/s, acc=0.926, loss=0.192]\n",
      "Epoch 37: 100%|██████████| 34/34 [00:00<00:00, 253.92batch/s, acc=0.926, loss=0.191]\n",
      "Epoch 38: 100%|██████████| 34/34 [00:00<00:00, 216.83batch/s, acc=0.926, loss=0.189]\n",
      "Epoch 39: 100%|██████████| 34/34 [00:00<00:00, 191.96batch/s, acc=0.926, loss=0.188]\n",
      "Epoch 40: 100%|██████████| 34/34 [00:00<00:00, 94.71batch/s, acc=0.926, loss=0.186] \n",
      "Epoch 41: 100%|██████████| 34/34 [00:00<00:00, 159.44batch/s, acc=0.926, loss=0.185]\n",
      "Epoch 42: 100%|██████████| 34/34 [00:00<00:00, 238.22batch/s, acc=0.926, loss=0.183]\n",
      "Epoch 43: 100%|██████████| 34/34 [00:00<00:00, 179.69batch/s, acc=0.926, loss=0.182]\n",
      "Epoch 44: 100%|██████████| 34/34 [00:00<00:00, 142.25batch/s, acc=0.926, loss=0.18] \n",
      "Epoch 45: 100%|██████████| 34/34 [00:00<00:00, 165.58batch/s, acc=0.926, loss=0.179]\n",
      "Epoch 46: 100%|██████████| 34/34 [00:00<00:00, 192.26batch/s, acc=0.926, loss=0.177]\n",
      "Epoch 47: 100%|██████████| 34/34 [00:00<00:00, 147.56batch/s, acc=0.926, loss=0.176]\n",
      "Epoch 48: 100%|██████████| 34/34 [00:00<00:00, 230.18batch/s, acc=0.926, loss=0.174]\n",
      "Epoch 49: 100%|██████████| 34/34 [00:00<00:00, 166.17batch/s, acc=0.926, loss=0.173]\n",
      "Epoch 50: 100%|██████████| 34/34 [00:00<00:00, 101.24batch/s, acc=0.926, loss=0.172]\n",
      "Epoch 51: 100%|██████████| 34/34 [00:00<00:00, 187.49batch/s, acc=0.926, loss=0.17] \n",
      "Epoch 52: 100%|██████████| 34/34 [00:00<00:00, 229.02batch/s, acc=0.926, loss=0.169]\n",
      "Epoch 53: 100%|██████████| 34/34 [00:00<00:00, 229.67batch/s, acc=0.926, loss=0.167]\n",
      "Epoch 54: 100%|██████████| 34/34 [00:00<00:00, 223.88batch/s, acc=0.926, loss=0.166]\n",
      "Epoch 55: 100%|██████████| 34/34 [00:00<00:00, 168.88batch/s, acc=0.926, loss=0.164]\n",
      "Epoch 56: 100%|██████████| 34/34 [00:00<00:00, 214.24batch/s, acc=0.926, loss=0.163]\n",
      "Epoch 57: 100%|██████████| 34/34 [00:00<00:00, 207.95batch/s, acc=0.926, loss=0.162]\n",
      "Epoch 58: 100%|██████████| 34/34 [00:00<00:00, 92.20batch/s, acc=0.926, loss=0.16]  \n",
      "Epoch 59: 100%|██████████| 34/34 [00:00<00:00, 268.63batch/s, acc=0.926, loss=0.159]\n",
      "Epoch 60: 100%|██████████| 34/34 [00:00<00:00, 284.54batch/s, acc=0.926, loss=0.158]\n",
      "Epoch 61: 100%|██████████| 34/34 [00:00<00:00, 273.55batch/s, acc=0.926, loss=0.156]\n",
      "Epoch 62: 100%|██████████| 34/34 [00:00<00:00, 275.08batch/s, acc=0.926, loss=0.155]\n",
      "Epoch 63: 100%|██████████| 34/34 [00:00<00:00, 280.90batch/s, acc=0.926, loss=0.154]\n",
      "Epoch 64: 100%|██████████| 34/34 [00:00<00:00, 283.62batch/s, acc=0.926, loss=0.152]\n",
      "Epoch 65: 100%|██████████| 34/34 [00:00<00:00, 219.01batch/s, acc=0.926, loss=0.151]\n",
      "Epoch 66: 100%|██████████| 34/34 [00:00<00:00, 123.32batch/s, acc=0.926, loss=0.15] \n",
      "Epoch 67: 100%|██████████| 34/34 [00:00<00:00, 188.25batch/s, acc=0.926, loss=0.148]\n",
      "Epoch 68: 100%|██████████| 34/34 [00:00<00:00, 247.53batch/s, acc=0.926, loss=0.147]\n",
      "Epoch 69: 100%|██████████| 34/34 [00:00<00:00, 235.29batch/s, acc=0.926, loss=0.146]\n",
      "Epoch 70: 100%|██████████| 34/34 [00:00<00:00, 231.63batch/s, acc=0.926, loss=0.144]\n",
      "Epoch 71: 100%|██████████| 34/34 [00:00<00:00, 260.06batch/s, acc=0.926, loss=0.143]\n",
      "Epoch 72: 100%|██████████| 34/34 [00:00<00:00, 255.64batch/s, acc=0.926, loss=0.142]\n",
      "Epoch 73: 100%|██████████| 34/34 [00:00<00:00, 255.84batch/s, acc=0.926, loss=0.141]\n",
      "Epoch 74: 100%|██████████| 34/34 [00:00<00:00, 111.87batch/s, acc=0.926, loss=0.139]\n",
      "Epoch 75: 100%|██████████| 34/34 [00:00<00:00, 196.00batch/s, acc=0.926, loss=0.138]\n",
      "Epoch 76: 100%|██████████| 34/34 [00:00<00:00, 228.71batch/s, acc=0.926, loss=0.137]\n",
      "Epoch 77: 100%|██████████| 34/34 [00:00<00:00, 139.03batch/s, acc=0.926, loss=0.136]\n",
      "Epoch 78: 100%|██████████| 34/34 [00:00<00:00, 234.65batch/s, acc=0.926, loss=0.135]\n",
      "Epoch 79: 100%|██████████| 34/34 [00:00<00:00, 262.73batch/s, acc=0.926, loss=0.133]\n",
      "Epoch 80: 100%|██████████| 34/34 [00:00<00:00, 253.15batch/s, acc=0.926, loss=0.132]\n",
      "Epoch 81: 100%|██████████| 34/34 [00:00<00:00, 114.28batch/s, acc=0.926, loss=0.131]\n",
      "Epoch 82: 100%|██████████| 34/34 [00:00<00:00, 123.42batch/s, acc=0.926, loss=0.13] \n",
      "Epoch 83: 100%|██████████| 34/34 [00:00<00:00, 243.55batch/s, acc=0.926, loss=0.129]\n",
      "Epoch 84: 100%|██████████| 34/34 [00:00<00:00, 278.95batch/s, acc=0.926, loss=0.127]\n",
      "Epoch 85: 100%|██████████| 34/34 [00:00<00:00, 149.85batch/s, acc=0.926, loss=0.126]\n",
      "Epoch 86: 100%|██████████| 34/34 [00:00<00:00, 266.69batch/s, acc=0.926, loss=0.125]\n",
      "Epoch 87: 100%|██████████| 34/34 [00:00<00:00, 164.55batch/s, acc=0.926, loss=0.124]\n",
      "Epoch 88: 100%|██████████| 34/34 [00:00<00:00, 105.50batch/s, acc=0.926, loss=0.123]\n",
      "Epoch 89: 100%|██████████| 34/34 [00:00<00:00, 167.54batch/s, acc=0.926, loss=0.122]\n",
      "Epoch 90: 100%|██████████| 34/34 [00:00<00:00, 270.63batch/s, acc=0.926, loss=0.121]\n",
      "Epoch 91: 100%|██████████| 34/34 [00:00<00:00, 276.35batch/s, acc=0.926, loss=0.12] \n",
      "Epoch 92: 100%|██████████| 34/34 [00:00<00:00, 280.87batch/s, acc=0.926, loss=0.119]\n",
      "Epoch 93: 100%|██████████| 34/34 [00:00<00:00, 258.98batch/s, acc=0.926, loss=0.118]\n",
      "Epoch 94: 100%|██████████| 34/34 [00:00<00:00, 274.99batch/s, acc=0.926, loss=0.117]\n",
      "Epoch 95: 100%|██████████| 34/34 [00:00<00:00, 102.67batch/s, acc=0.926, loss=0.115]\n",
      "Epoch 96: 100%|██████████| 34/34 [00:00<00:00, 214.22batch/s, acc=0.926, loss=0.114] \n",
      "Epoch 97: 100%|██████████| 34/34 [00:00<00:00, 258.26batch/s, acc=0.926, loss=0.113] \n",
      "Epoch 98: 100%|██████████| 34/34 [00:00<00:00, 183.72batch/s, acc=0.926, loss=0.112] \n",
      "Epoch 99: 100%|██████████| 34/34 [00:00<00:00, 192.23batch/s, acc=0.926, loss=0.111] \n",
      "Epoch 100: 100%|██████████| 34/34 [00:00<00:00, 194.62batch/s, acc=0.926, loss=0.11]  \n",
      "Epoch 101: 100%|██████████| 34/34 [00:00<00:00, 185.32batch/s, acc=0.926, loss=0.109] \n",
      "Epoch 102: 100%|██████████| 34/34 [00:00<00:00, 234.28batch/s, acc=0.926, loss=0.108] \n",
      "Epoch 103: 100%|██████████| 34/34 [00:00<00:00, 96.44batch/s, acc=0.926, loss=0.107]  \n",
      "Epoch 104: 100%|██████████| 34/34 [00:00<00:00, 282.59batch/s, acc=0.926, loss=0.106] \n",
      "Epoch 105: 100%|██████████| 34/34 [00:00<00:00, 281.75batch/s, acc=0.926, loss=0.105] \n",
      "Epoch 106: 100%|██████████| 34/34 [00:00<00:00, 275.85batch/s, acc=0.926, loss=0.104] \n",
      "Epoch 107: 100%|██████████| 34/34 [00:00<00:00, 270.22batch/s, acc=0.926, loss=0.104] \n",
      "Epoch 108: 100%|██████████| 34/34 [00:00<00:00, 230.94batch/s, acc=0.926, loss=0.103] \n",
      "Epoch 109: 100%|██████████| 34/34 [00:00<00:00, 111.56batch/s, acc=0.926, loss=0.102] \n",
      "Epoch 110: 100%|██████████| 34/34 [00:00<00:00, 228.35batch/s, acc=0.926, loss=0.101] \n",
      "Epoch 111: 100%|██████████| 34/34 [00:00<00:00, 256.16batch/s, acc=0.963, loss=0.0998]\n",
      "Epoch 112: 100%|██████████| 34/34 [00:00<00:00, 244.74batch/s, acc=0.963, loss=0.0989]\n",
      "Epoch 113: 100%|██████████| 34/34 [00:00<00:00, 256.48batch/s, acc=0.963, loss=0.098] \n",
      "Epoch 114: 100%|██████████| 34/34 [00:00<00:00, 208.87batch/s, acc=0.963, loss=0.0971]\n",
      "Epoch 115: 100%|██████████| 34/34 [00:00<00:00, 79.09batch/s, acc=1, loss=0.0962]    \n",
      "Epoch 116: 100%|██████████| 34/34 [00:00<00:00, 167.65batch/s, acc=1, loss=0.0953]   \n",
      "Epoch 117: 100%|██████████| 34/34 [00:00<00:00, 187.19batch/s, acc=1, loss=0.0944]    \n",
      "Epoch 118: 100%|██████████| 34/34 [00:00<00:00, 199.38batch/s, acc=1, loss=0.0936]    \n",
      "Epoch 119: 100%|██████████| 34/34 [00:00<00:00, 192.79batch/s, acc=1, loss=0.0927]   \n",
      "Epoch 120: 100%|██████████| 34/34 [00:00<00:00, 94.61batch/s, acc=1, loss=0.0919]     \n",
      "Epoch 121: 100%|██████████| 34/34 [00:00<00:00, 270.20batch/s, acc=1, loss=0.091]     \n",
      "Epoch 122: 100%|██████████| 34/34 [00:00<00:00, 254.57batch/s, acc=1, loss=0.0902]    \n",
      "Epoch 123: 100%|██████████| 34/34 [00:00<00:00, 271.41batch/s, acc=1, loss=0.0893]    \n",
      "Epoch 124: 100%|██████████| 34/34 [00:00<00:00, 222.78batch/s, acc=1, loss=0.0885]    \n",
      "Epoch 125: 100%|██████████| 34/34 [00:00<00:00, 101.32batch/s, acc=1, loss=0.0877]   \n",
      "Epoch 126: 100%|██████████| 34/34 [00:00<00:00, 276.01batch/s, acc=1, loss=0.0869]    \n",
      "Epoch 127: 100%|██████████| 34/34 [00:00<00:00, 275.46batch/s, acc=1, loss=0.0861]    \n",
      "Epoch 128: 100%|██████████| 34/34 [00:00<00:00, 210.09batch/s, acc=1, loss=0.0853]    \n",
      "Epoch 129: 100%|██████████| 34/34 [00:00<00:00, 249.51batch/s, acc=1, loss=0.0845]    \n",
      "Epoch 130: 100%|██████████| 34/34 [00:00<00:00, 121.69batch/s, acc=1, loss=0.0837]    \n",
      "Epoch 131: 100%|██████████| 34/34 [00:00<00:00, 121.93batch/s, acc=1, loss=0.083]     \n",
      "Epoch 132: 100%|██████████| 34/34 [00:00<00:00, 204.62batch/s, acc=1, loss=0.0822]    \n",
      "Epoch 133: 100%|██████████| 34/34 [00:00<00:00, 224.78batch/s, acc=1, loss=0.0814]    \n",
      "Epoch 134: 100%|██████████| 34/34 [00:00<00:00, 202.25batch/s, acc=1, loss=0.0807]    \n",
      "Epoch 135: 100%|██████████| 34/34 [00:00<00:00, 112.25batch/s, acc=1, loss=0.0799]    \n",
      "Epoch 136: 100%|██████████| 34/34 [00:00<00:00, 145.36batch/s, acc=1, loss=0.0792]   \n",
      "Epoch 137: 100%|██████████| 34/34 [00:00<00:00, 198.50batch/s, acc=1, loss=0.0784]    \n",
      "Epoch 138: 100%|██████████| 34/34 [00:00<00:00, 169.36batch/s, acc=1, loss=0.0777]    \n",
      "Epoch 139: 100%|██████████| 34/34 [00:00<00:00, 225.87batch/s, acc=1, loss=0.077]     \n",
      "Epoch 140: 100%|██████████| 34/34 [00:00<00:00, 202.62batch/s, acc=1, loss=0.0763]    \n",
      "Epoch 141: 100%|██████████| 34/34 [00:00<00:00, 242.03batch/s, acc=1, loss=0.0756]    \n",
      "Epoch 142: 100%|██████████| 34/34 [00:00<00:00, 238.47batch/s, acc=1, loss=0.0749]    \n",
      "Epoch 143: 100%|██████████| 34/34 [00:00<00:00, 157.52batch/s, acc=1, loss=0.0742]    \n",
      "Epoch 144: 100%|██████████| 34/34 [00:00<00:00, 88.04batch/s, acc=1, loss=0.0735]    \n",
      "Epoch 145: 100%|██████████| 34/34 [00:00<00:00, 240.33batch/s, acc=1, loss=0.0728]    \n",
      "Epoch 146: 100%|██████████| 34/34 [00:00<00:00, 210.71batch/s, acc=1, loss=0.0721]    \n",
      "Epoch 147: 100%|██████████| 34/34 [00:00<00:00, 215.23batch/s, acc=1, loss=0.0714]    \n",
      "Epoch 148: 100%|██████████| 34/34 [00:00<00:00, 217.49batch/s, acc=1, loss=0.0708]    \n",
      "Epoch 149: 100%|██████████| 34/34 [00:00<00:00, 182.04batch/s, acc=1, loss=0.0701]    \n",
      "Epoch 150: 100%|██████████| 34/34 [00:00<00:00, 210.53batch/s, acc=1, loss=0.0694]    \n",
      "Epoch 151: 100%|██████████| 34/34 [00:00<00:00, 165.23batch/s, acc=1, loss=0.0688]    \n",
      "Epoch 152: 100%|██████████| 34/34 [00:00<00:00, 227.46batch/s, acc=1, loss=0.0681]    \n",
      "Epoch 153: 100%|██████████| 34/34 [00:00<00:00, 201.32batch/s, acc=1, loss=0.0675]    \n",
      "Epoch 154: 100%|██████████| 34/34 [00:00<00:00, 208.41batch/s, acc=1, loss=0.0669]    \n",
      "Epoch 155: 100%|██████████| 34/34 [00:00<00:00, 92.63batch/s, acc=1, loss=0.0662]     \n",
      "Epoch 156: 100%|██████████| 34/34 [00:00<00:00, 242.69batch/s, acc=1, loss=0.0656]    \n",
      "Epoch 157: 100%|██████████| 34/34 [00:00<00:00, 162.62batch/s, acc=1, loss=0.065]     \n",
      "Epoch 158: 100%|██████████| 34/34 [00:00<00:00, 121.02batch/s, acc=1, loss=0.0644]    \n",
      "Epoch 159: 100%|██████████| 34/34 [00:00<00:00, 150.21batch/s, acc=1, loss=0.0638]    \n",
      "Epoch 160: 100%|██████████| 34/34 [00:00<00:00, 278.02batch/s, acc=1, loss=0.0632]    \n",
      "Epoch 161: 100%|██████████| 34/34 [00:00<00:00, 269.24batch/s, acc=1, loss=0.0626]    \n",
      "Epoch 162: 100%|██████████| 34/34 [00:00<00:00, 278.23batch/s, acc=1, loss=0.062]     \n",
      "Epoch 163: 100%|██████████| 34/34 [00:00<00:00, 96.76batch/s, acc=1, loss=0.0614]     \n",
      "Epoch 164: 100%|██████████| 34/34 [00:00<00:00, 206.53batch/s, acc=1, loss=0.0608]    \n",
      "Epoch 165: 100%|██████████| 34/34 [00:00<00:00, 271.53batch/s, acc=1, loss=0.0603]    \n",
      "Epoch 166: 100%|██████████| 34/34 [00:00<00:00, 276.95batch/s, acc=1, loss=0.0597]    \n",
      "Epoch 167: 100%|██████████| 34/34 [00:00<00:00, 102.61batch/s, acc=1, loss=0.0591]    \n",
      "Epoch 168: 100%|██████████| 34/34 [00:00<00:00, 268.84batch/s, acc=1, loss=0.0586]    \n",
      "Epoch 169: 100%|██████████| 34/34 [00:00<00:00, 271.27batch/s, acc=1, loss=0.058]     \n",
      "Epoch 170: 100%|██████████| 34/34 [00:00<00:00, 212.64batch/s, acc=1, loss=0.0575]    \n",
      "Epoch 171: 100%|██████████| 34/34 [00:00<00:00, 280.86batch/s, acc=1, loss=0.0569]    \n",
      "Epoch 172: 100%|██████████| 34/34 [00:00<00:00, 278.50batch/s, acc=1, loss=0.0564]    \n",
      "Epoch 173: 100%|██████████| 34/34 [00:00<00:00, 103.25batch/s, acc=1, loss=0.0559]    \n",
      "Epoch 174: 100%|██████████| 34/34 [00:00<00:00, 143.24batch/s, acc=1, loss=0.0553]    \n",
      "Epoch 175: 100%|██████████| 34/34 [00:00<00:00, 241.45batch/s, acc=1, loss=0.0548]    \n",
      "Epoch 176: 100%|██████████| 34/34 [00:00<00:00, 210.93batch/s, acc=1, loss=0.0543]    \n",
      "Epoch 177: 100%|██████████| 34/34 [00:00<00:00, 271.33batch/s, acc=1, loss=0.0538]    \n",
      "Epoch 178: 100%|██████████| 34/34 [00:00<00:00, 280.38batch/s, acc=1, loss=0.0533]    \n",
      "Epoch 179: 100%|██████████| 34/34 [00:00<00:00, 143.17batch/s, acc=1, loss=0.0528]    \n",
      "Epoch 180: 100%|██████████| 34/34 [00:00<00:00, 95.60batch/s, acc=1, loss=0.0523]     \n",
      "Epoch 181: 100%|██████████| 34/34 [00:00<00:00, 111.60batch/s, acc=1, loss=0.0518]    \n",
      "Epoch 182: 100%|██████████| 34/34 [00:00<00:00, 127.78batch/s, acc=1, loss=0.0513]    \n",
      "Epoch 183: 100%|██████████| 34/34 [00:00<00:00, 92.63batch/s, acc=1, loss=0.0508]     \n",
      "Epoch 184: 100%|██████████| 34/34 [00:00<00:00, 192.35batch/s, acc=1, loss=0.0503]    \n",
      "Epoch 185: 100%|██████████| 34/34 [00:00<00:00, 204.47batch/s, acc=1, loss=0.0498]    \n",
      "Epoch 186: 100%|██████████| 34/34 [00:00<00:00, 276.31batch/s, acc=1, loss=0.0494]    \n",
      "Epoch 187: 100%|██████████| 34/34 [00:00<00:00, 102.04batch/s, acc=1, loss=0.0489]    \n",
      "Epoch 188: 100%|██████████| 34/34 [00:00<00:00, 268.34batch/s, acc=1, loss=0.0484]    \n",
      "Epoch 189: 100%|██████████| 34/34 [00:00<00:00, 276.68batch/s, acc=1, loss=0.048]     \n",
      "Epoch 190: 100%|██████████| 34/34 [00:00<00:00, 270.90batch/s, acc=1, loss=0.0475]    \n",
      "Epoch 191: 100%|██████████| 34/34 [00:00<00:00, 217.11batch/s, acc=1, loss=0.0471]    \n",
      "Epoch 192: 100%|██████████| 34/34 [00:00<00:00, 112.67batch/s, acc=1, loss=0.0466]    \n",
      "Epoch 193: 100%|██████████| 34/34 [00:00<00:00, 205.45batch/s, acc=1, loss=0.0462]    \n",
      "Epoch 194: 100%|██████████| 34/34 [00:00<00:00, 243.45batch/s, acc=1, loss=0.0458]    \n",
      "Epoch 195: 100%|██████████| 34/34 [00:00<00:00, 268.98batch/s, acc=1, loss=0.0453]    \n",
      "Epoch 196: 100%|██████████| 34/34 [00:00<00:00, 208.37batch/s, acc=1, loss=0.0449]    \n",
      "Epoch 197: 100%|██████████| 34/34 [00:00<00:00, 108.03batch/s, acc=1, loss=0.0445]    \n",
      "Epoch 198: 100%|██████████| 34/34 [00:00<00:00, 199.75batch/s, acc=1, loss=0.0441]    \n",
      "Epoch 199: 100%|██████████| 34/34 [00:00<00:00, 251.23batch/s, acc=1, loss=0.0436]    \n",
      "Epoch 200: 100%|██████████| 34/34 [00:00<00:00, 255.10batch/s, acc=1, loss=0.0432]    \n",
      "Epoch 201: 100%|██████████| 34/34 [00:00<00:00, 117.92batch/s, acc=1, loss=0.0428]    \n",
      "Epoch 202: 100%|██████████| 34/34 [00:00<00:00, 243.97batch/s, acc=1, loss=0.0424]    \n",
      "Epoch 203: 100%|██████████| 34/34 [00:00<00:00, 260.29batch/s, acc=1, loss=0.042]     \n",
      "Epoch 204: 100%|██████████| 34/34 [00:00<00:00, 120.64batch/s, acc=1, loss=0.0416]    \n",
      "Epoch 205: 100%|██████████| 34/34 [00:00<00:00, 196.54batch/s, acc=1, loss=0.0412]    \n",
      "Epoch 206: 100%|██████████| 34/34 [00:00<00:00, 209.84batch/s, acc=1, loss=0.0409]    \n",
      "Epoch 207: 100%|██████████| 34/34 [00:00<00:00, 267.77batch/s, acc=1, loss=0.0405]    \n",
      "Epoch 208: 100%|██████████| 34/34 [00:00<00:00, 269.50batch/s, acc=1, loss=0.0401]    \n",
      "Epoch 209: 100%|██████████| 34/34 [00:00<00:00, 239.61batch/s, acc=1, loss=0.0397]    \n",
      "Epoch 210: 100%|██████████| 34/34 [00:00<00:00, 101.52batch/s, acc=1, loss=0.0394]    \n",
      "Epoch 211: 100%|██████████| 34/34 [00:00<00:00, 217.90batch/s, acc=1, loss=0.039]     \n",
      "Epoch 212: 100%|██████████| 34/34 [00:00<00:00, 259.76batch/s, acc=1, loss=0.0386]    \n",
      "Epoch 213: 100%|██████████| 34/34 [00:00<00:00, 235.89batch/s, acc=1, loss=0.0383]    \n",
      "Epoch 214: 100%|██████████| 34/34 [00:00<00:00, 269.90batch/s, acc=1, loss=0.0379]    \n",
      "Epoch 215: 100%|██████████| 34/34 [00:00<00:00, 271.80batch/s, acc=1, loss=0.0376]    \n",
      "Epoch 216: 100%|██████████| 34/34 [00:00<00:00, 216.07batch/s, acc=1, loss=0.0372]    \n",
      "Epoch 217: 100%|██████████| 34/34 [00:00<00:00, 245.01batch/s, acc=1, loss=0.0369]    \n",
      "Epoch 218: 100%|██████████| 34/34 [00:00<00:00, 99.36batch/s, acc=1, loss=0.0365]     \n",
      "Epoch 219: 100%|██████████| 34/34 [00:00<00:00, 261.56batch/s, acc=1, loss=0.0362]    \n",
      "Epoch 220: 100%|██████████| 34/34 [00:00<00:00, 251.81batch/s, acc=1, loss=0.0358]    \n",
      "Epoch 221: 100%|██████████| 34/34 [00:00<00:00, 106.52batch/s, acc=1, loss=0.0355]    \n",
      "Epoch 222: 100%|██████████| 34/34 [00:00<00:00, 133.74batch/s, acc=1, loss=0.0352]    \n",
      "Epoch 223: 100%|██████████| 34/34 [00:00<00:00, 271.68batch/s, acc=1, loss=0.0349]    \n",
      "Epoch 224: 100%|██████████| 34/34 [00:00<00:00, 131.20batch/s, acc=1, loss=0.0345]    \n",
      "Epoch 225: 100%|██████████| 34/34 [00:00<00:00, 150.77batch/s, acc=1, loss=0.0342]    \n",
      "Epoch 226: 100%|██████████| 34/34 [00:00<00:00, 274.69batch/s, acc=1, loss=0.0339]    \n",
      "Epoch 227: 100%|██████████| 34/34 [00:00<00:00, 266.36batch/s, acc=1, loss=0.0336]    \n",
      "Epoch 228: 100%|██████████| 34/34 [00:00<00:00, 278.03batch/s, acc=1, loss=0.0333]    \n",
      "Epoch 229: 100%|██████████| 34/34 [00:00<00:00, 273.79batch/s, acc=1, loss=0.033]     \n",
      "Epoch 230: 100%|██████████| 34/34 [00:00<00:00, 211.57batch/s, acc=1, loss=0.0327]    \n",
      "Epoch 231: 100%|██████████| 34/34 [00:00<00:00, 98.20batch/s, acc=1, loss=0.0324]     \n",
      "Epoch 232: 100%|██████████| 34/34 [00:00<00:00, 262.18batch/s, acc=1, loss=0.0321]    \n",
      "Epoch 233: 100%|██████████| 34/34 [00:00<00:00, 241.55batch/s, acc=1, loss=0.0318]    \n",
      "Epoch 234: 100%|██████████| 34/34 [00:00<00:00, 91.55batch/s, acc=1, loss=0.0315]     \n",
      "Epoch 235: 100%|██████████| 34/34 [00:00<00:00, 256.89batch/s, acc=1, loss=0.0312]    \n",
      "Epoch 236: 100%|██████████| 34/34 [00:00<00:00, 273.31batch/s, acc=1, loss=0.0309]    \n",
      "Epoch 237: 100%|██████████| 34/34 [00:00<00:00, 269.72batch/s, acc=1, loss=0.0307]    \n",
      "Epoch 238: 100%|██████████| 34/34 [00:00<00:00, 106.63batch/s, acc=1, loss=0.0304]    \n",
      "Epoch 239: 100%|██████████| 34/34 [00:00<00:00, 190.88batch/s, acc=1, loss=0.0301]    \n",
      "Epoch 240: 100%|██████████| 34/34 [00:00<00:00, 133.39batch/s, acc=1, loss=0.0298]    \n",
      "Epoch 241: 100%|██████████| 34/34 [00:00<00:00, 137.01batch/s, acc=1, loss=0.0296]    \n",
      "Epoch 242: 100%|██████████| 34/34 [00:00<00:00, 129.79batch/s, acc=1, loss=0.0293]    \n",
      "Epoch 243: 100%|██████████| 34/34 [00:00<00:00, 103.96batch/s, acc=1, loss=0.029]     \n",
      "Epoch 244: 100%|██████████| 34/34 [00:00<00:00, 235.74batch/s, acc=1, loss=0.0288]    \n",
      "Epoch 245: 100%|██████████| 34/34 [00:00<00:00, 283.95batch/s, acc=1, loss=0.0285]    \n",
      "Epoch 246: 100%|██████████| 34/34 [00:00<00:00, 155.72batch/s, acc=1, loss=0.0283]    \n",
      "Epoch 247: 100%|██████████| 34/34 [00:00<00:00, 128.74batch/s, acc=1, loss=0.028]     \n",
      "Epoch 248: 100%|██████████| 34/34 [00:00<00:00, 254.18batch/s, acc=1, loss=0.0278]    \n",
      "Epoch 249: 100%|██████████| 34/34 [00:00<00:00, 262.81batch/s, acc=1, loss=0.0275]    \n",
      "Epoch 250: 100%|██████████| 34/34 [00:00<00:00, 200.25batch/s, acc=1, loss=0.0273]    \n",
      "Epoch 251: 100%|██████████| 34/34 [00:00<00:00, 106.07batch/s, acc=1, loss=0.0271]    \n",
      "Epoch 252: 100%|██████████| 34/34 [00:00<00:00, 244.07batch/s, acc=1, loss=0.0268]    \n",
      "Epoch 253: 100%|██████████| 34/34 [00:00<00:00, 248.54batch/s, acc=1, loss=0.0266]    \n",
      "Epoch 254: 100%|██████████| 34/34 [00:00<00:00, 77.89batch/s, acc=1, loss=0.0263]     \n",
      "Epoch 255: 100%|██████████| 34/34 [00:00<00:00, 239.04batch/s, acc=1, loss=0.0261]    \n",
      "Epoch 256: 100%|██████████| 34/34 [00:00<00:00, 334.63batch/s, acc=1, loss=0.0259]    \n",
      "Epoch 257: 100%|██████████| 34/34 [00:00<00:00, 129.83batch/s, acc=1, loss=0.0257]    \n",
      "Epoch 258: 100%|██████████| 34/34 [00:00<00:00, 117.58batch/s, acc=1, loss=0.0254]    \n",
      "Epoch 259: 100%|██████████| 34/34 [00:00<00:00, 68.66batch/s, acc=1, loss=0.0252]     \n",
      "Epoch 260: 100%|██████████| 34/34 [00:00<00:00, 193.87batch/s, acc=1, loss=0.025]     \n",
      "Epoch 261: 100%|██████████| 34/34 [00:00<00:00, 89.00batch/s, acc=1, loss=0.0248]     \n",
      "Epoch 262: 100%|██████████| 34/34 [00:00<00:00, 109.52batch/s, acc=1, loss=0.0246]    \n",
      "Epoch 263: 100%|██████████| 34/34 [00:00<00:00, 194.28batch/s, acc=1, loss=0.0244]    \n",
      "Epoch 264: 100%|██████████| 34/34 [00:00<00:00, 84.40batch/s, acc=1, loss=0.0242]     \n",
      "Epoch 265: 100%|██████████| 34/34 [00:00<00:00, 254.94batch/s, acc=1, loss=0.0239]    \n",
      "Epoch 266: 100%|██████████| 34/34 [00:00<00:00, 113.73batch/s, acc=1, loss=0.0237]    \n",
      "Epoch 267: 100%|██████████| 34/34 [00:00<00:00, 193.46batch/s, acc=1, loss=0.0235]    \n",
      "Epoch 268: 100%|██████████| 34/34 [00:00<00:00, 312.69batch/s, acc=1, loss=0.0233]    \n",
      "Epoch 269: 100%|██████████| 34/34 [00:00<00:00, 116.28batch/s, acc=1, loss=0.0231]    \n",
      "Epoch 270: 100%|██████████| 34/34 [00:00<00:00, 212.11batch/s, acc=1, loss=0.0229]    \n",
      "Epoch 271: 100%|██████████| 34/34 [00:00<00:00, 339.18batch/s, acc=1, loss=0.0228]    \n",
      "Epoch 272: 100%|██████████| 34/34 [00:00<00:00, 118.93batch/s, acc=1, loss=0.0226]    \n",
      "Epoch 273: 100%|██████████| 34/34 [00:00<00:00, 315.44batch/s, acc=1, loss=0.0224]    \n",
      "Epoch 274: 100%|██████████| 34/34 [00:00<00:00, 368.35batch/s, acc=1, loss=0.0222]    \n",
      "Epoch 275: 100%|██████████| 34/34 [00:00<00:00, 88.79batch/s, acc=1, loss=0.022]      \n",
      "Epoch 276: 100%|██████████| 34/34 [00:00<00:00, 266.12batch/s, acc=1, loss=0.0218]    \n",
      "Epoch 277: 100%|██████████| 34/34 [00:00<00:00, 135.81batch/s, acc=1, loss=0.0216]    \n",
      "Epoch 278: 100%|██████████| 34/34 [00:00<00:00, 168.53batch/s, acc=1, loss=0.0215]    \n",
      "Epoch 279: 100%|██████████| 34/34 [00:00<00:00, 258.53batch/s, acc=1, loss=0.0213]    \n",
      "Epoch 280: 100%|██████████| 34/34 [00:00<00:00, 142.08batch/s, acc=1, loss=0.0211]    \n",
      "Epoch 281: 100%|██████████| 34/34 [00:00<00:00, 227.31batch/s, acc=1, loss=0.0209]    \n",
      "Epoch 282: 100%|██████████| 34/34 [00:00<00:00, 148.78batch/s, acc=1, loss=0.0208]    \n",
      "Epoch 283: 100%|██████████| 34/34 [00:00<00:00, 137.91batch/s, acc=1, loss=0.0206]    \n",
      "Epoch 284: 100%|██████████| 34/34 [00:00<00:00, 376.72batch/s, acc=1, loss=0.0204]    \n",
      "Epoch 285: 100%|██████████| 34/34 [00:00<00:00, 93.42batch/s, acc=1, loss=0.0203]     \n",
      "Epoch 286: 100%|██████████| 34/34 [00:00<00:00, 307.00batch/s, acc=1, loss=0.0201]    \n",
      "Epoch 287: 100%|██████████| 34/34 [00:00<00:00, 112.79batch/s, acc=1, loss=0.0199]    \n",
      "Epoch 288: 100%|██████████| 34/34 [00:00<00:00, 214.98batch/s, acc=1, loss=0.0198]    \n",
      "Epoch 289: 100%|██████████| 34/34 [00:00<00:00, 126.99batch/s, acc=1, loss=0.0196]    \n",
      "Epoch 290: 100%|██████████| 34/34 [00:00<00:00, 154.96batch/s, acc=1, loss=0.0194]    \n",
      "Epoch 291: 100%|██████████| 34/34 [00:00<00:00, 330.05batch/s, acc=1, loss=0.0193]    \n",
      "Epoch 292: 100%|██████████| 34/34 [00:00<00:00, 146.64batch/s, acc=1, loss=0.0191]    \n",
      "Epoch 293: 100%|██████████| 34/34 [00:00<00:00, 127.81batch/s, acc=1, loss=0.019]     \n",
      "Epoch 294: 100%|██████████| 34/34 [00:00<00:00, 294.85batch/s, acc=1, loss=0.0188]    \n",
      "Epoch 295: 100%|██████████| 34/34 [00:00<00:00, 111.50batch/s, acc=1, loss=0.0187]    \n",
      "Epoch 296: 100%|██████████| 34/34 [00:00<00:00, 183.33batch/s, acc=1, loss=0.0185]    \n",
      "Epoch 297: 100%|██████████| 34/34 [00:00<00:00, 157.25batch/s, acc=1, loss=0.0184]    \n",
      "Epoch 298: 100%|██████████| 34/34 [00:00<00:00, 102.11batch/s, acc=1, loss=0.0182]    \n",
      "Epoch 299: 100%|██████████| 34/34 [00:00<00:00, 177.81batch/s, acc=1, loss=0.0181]    \n",
      "Epoch 300: 100%|██████████| 34/34 [00:00<00:00, 96.61batch/s, acc=1, loss=0.018]      \n",
      "Epoch 301: 100%|██████████| 34/34 [00:00<00:00, 119.24batch/s, acc=1, loss=0.0178]    \n",
      "Epoch 302: 100%|██████████| 34/34 [00:00<00:00, 174.50batch/s, acc=1, loss=0.0177]    \n",
      "Epoch 303: 100%|██████████| 34/34 [00:00<00:00, 121.03batch/s, acc=1, loss=0.0175]    \n",
      "Epoch 304: 100%|██████████| 34/34 [00:00<00:00, 171.38batch/s, acc=1, loss=0.0174]    \n",
      "Epoch 305: 100%|██████████| 34/34 [00:00<00:00, 133.83batch/s, acc=1, loss=0.0173]    \n",
      "Epoch 306: 100%|██████████| 34/34 [00:00<00:00, 176.37batch/s, acc=1, loss=0.0171]    \n",
      "Epoch 307: 100%|██████████| 34/34 [00:00<00:00, 316.03batch/s, acc=1, loss=0.017]     \n",
      "Epoch 308: 100%|██████████| 34/34 [00:00<00:00, 98.87batch/s, acc=1, loss=0.0169]     \n",
      "Epoch 309: 100%|██████████| 34/34 [00:00<00:00, 280.59batch/s, acc=1, loss=0.0167]    \n",
      "Epoch 310: 100%|██████████| 34/34 [00:00<00:00, 110.37batch/s, acc=1, loss=0.0166]    \n",
      "Epoch 311: 100%|██████████| 34/34 [00:00<00:00, 143.33batch/s, acc=1, loss=0.0165]    \n",
      "Epoch 312: 100%|██████████| 34/34 [00:00<00:00, 110.65batch/s, acc=1, loss=0.0164]    \n",
      "Epoch 313: 100%|██████████| 34/34 [00:00<00:00, 141.80batch/s, acc=1, loss=0.0162]    \n",
      "Epoch 314: 100%|██████████| 34/34 [00:00<00:00, 352.68batch/s, acc=1, loss=0.0161]    \n",
      "Epoch 315: 100%|██████████| 34/34 [00:00<00:00, 88.32batch/s, acc=1, loss=0.016]      \n",
      "Epoch 316: 100%|██████████| 34/34 [00:00<00:00, 206.06batch/s, acc=1, loss=0.0159]    \n",
      "Epoch 317: 100%|██████████| 34/34 [00:00<00:00, 90.10batch/s, acc=1, loss=0.0158]     \n",
      "Epoch 318: 100%|██████████| 34/34 [00:00<00:00, 94.58batch/s, acc=1, loss=0.0156]     \n",
      "Epoch 319: 100%|██████████| 34/34 [00:00<00:00, 80.83batch/s, acc=1, loss=0.0155]     \n",
      "Epoch 320: 100%|██████████| 34/34 [00:00<00:00, 178.36batch/s, acc=1, loss=0.0154]    \n",
      "Epoch 321: 100%|██████████| 34/34 [00:00<00:00, 105.12batch/s, acc=1, loss=0.0153]    \n",
      "Epoch 322: 100%|██████████| 34/34 [00:00<00:00, 158.64batch/s, acc=1, loss=0.0152]    \n",
      "Epoch 323: 100%|██████████| 34/34 [00:00<00:00, 113.71batch/s, acc=1, loss=0.0151]    \n",
      "Epoch 324: 100%|██████████| 34/34 [00:00<00:00, 207.44batch/s, acc=1, loss=0.015]     \n",
      "Epoch 325: 100%|██████████| 34/34 [00:00<00:00, 139.91batch/s, acc=1, loss=0.0148]    \n",
      "Epoch 326: 100%|██████████| 34/34 [00:00<00:00, 141.75batch/s, acc=1, loss=0.0147]    \n",
      "Epoch 327: 100%|██████████| 34/34 [00:00<00:00, 245.22batch/s, acc=1, loss=0.0146]    \n",
      "Epoch 328: 100%|██████████| 34/34 [00:00<00:00, 108.20batch/s, acc=1, loss=0.0145]    \n",
      "Epoch 329: 100%|██████████| 34/34 [00:00<00:00, 226.56batch/s, acc=1, loss=0.0144]    \n",
      "Epoch 330: 100%|██████████| 34/34 [00:00<00:00, 244.99batch/s, acc=1, loss=0.0143]    \n",
      "Epoch 331: 100%|██████████| 34/34 [00:00<00:00, 127.89batch/s, acc=1, loss=0.0142]    \n",
      "Epoch 332: 100%|██████████| 34/34 [00:00<00:00, 157.42batch/s, acc=1, loss=0.0141]    \n",
      "Epoch 333: 100%|██████████| 34/34 [00:00<00:00, 211.30batch/s, acc=1, loss=0.014]     \n",
      "Epoch 334: 100%|██████████| 34/34 [00:00<00:00, 256.42batch/s, acc=1, loss=0.0139]    \n",
      "Epoch 335: 100%|██████████| 34/34 [00:00<00:00, 258.07batch/s, acc=1, loss=0.0138]    \n",
      "Epoch 336: 100%|██████████| 34/34 [00:00<00:00, 109.81batch/s, acc=1, loss=0.0137]    \n",
      "Epoch 337: 100%|██████████| 34/34 [00:00<00:00, 184.43batch/s, acc=1, loss=0.0136]    \n",
      "Epoch 338: 100%|██████████| 34/34 [00:00<00:00, 272.68batch/s, acc=1, loss=0.0135]    \n",
      "Epoch 339: 100%|██████████| 34/34 [00:00<00:00, 115.18batch/s, acc=1, loss=0.0134]    \n",
      "Epoch 340: 100%|██████████| 34/34 [00:00<00:00, 184.04batch/s, acc=1, loss=0.0133]    \n",
      "Epoch 341: 100%|██████████| 34/34 [00:00<00:00, 251.14batch/s, acc=1, loss=0.0132]    \n",
      "Epoch 342: 100%|██████████| 34/34 [00:00<00:00, 261.82batch/s, acc=1, loss=0.0131]    \n",
      "Epoch 343: 100%|██████████| 34/34 [00:00<00:00, 112.91batch/s, acc=1, loss=0.013]     \n",
      "Epoch 344: 100%|██████████| 34/34 [00:00<00:00, 179.58batch/s, acc=1, loss=0.0129]    \n",
      "Epoch 345: 100%|██████████| 34/34 [00:00<00:00, 189.20batch/s, acc=1, loss=0.0129]    \n",
      "Epoch 346: 100%|██████████| 34/34 [00:00<00:00, 249.73batch/s, acc=1, loss=0.0128]    \n",
      "Epoch 347: 100%|██████████| 34/34 [00:00<00:00, 116.28batch/s, acc=1, loss=0.0127]    \n",
      "Epoch 348: 100%|██████████| 34/34 [00:00<00:00, 133.86batch/s, acc=1, loss=0.0126]    \n",
      "Epoch 349: 100%|██████████| 34/34 [00:00<00:00, 167.02batch/s, acc=1, loss=0.0125]    \n",
      "Epoch 350: 100%|██████████| 34/34 [00:00<00:00, 195.06batch/s, acc=1, loss=0.0124]    \n",
      "Epoch 351: 100%|██████████| 34/34 [00:00<00:00, 139.50batch/s, acc=1, loss=0.0123]    \n",
      "Epoch 352: 100%|██████████| 34/34 [00:00<00:00, 145.74batch/s, acc=1, loss=0.0122]    \n",
      "Epoch 353: 100%|██████████| 34/34 [00:00<00:00, 243.60batch/s, acc=1, loss=0.0122]    \n",
      "Epoch 354: 100%|██████████| 34/34 [00:00<00:00, 206.04batch/s, acc=1, loss=0.0121]    \n",
      "Epoch 355: 100%|██████████| 34/34 [00:00<00:00, 249.26batch/s, acc=1, loss=0.012]     \n",
      "Epoch 356: 100%|██████████| 34/34 [00:00<00:00, 147.64batch/s, acc=1, loss=0.0119]    \n",
      "Epoch 357: 100%|██████████| 34/34 [00:00<00:00, 135.04batch/s, acc=1, loss=0.0118]    \n",
      "Epoch 358: 100%|██████████| 34/34 [00:00<00:00, 242.96batch/s, acc=1, loss=0.0118]    \n",
      "Epoch 359: 100%|██████████| 34/34 [00:00<00:00, 207.10batch/s, acc=1, loss=0.0117]    \n",
      "Epoch 360: 100%|██████████| 34/34 [00:00<00:00, 254.66batch/s, acc=1, loss=0.0116]    \n",
      "Epoch 361: 100%|██████████| 34/34 [00:00<00:00, 109.16batch/s, acc=1, loss=0.0115]    \n",
      "Epoch 362: 100%|██████████| 34/34 [00:00<00:00, 178.63batch/s, acc=1, loss=0.0114]    \n",
      "Epoch 363: 100%|██████████| 34/34 [00:00<00:00, 108.79batch/s, acc=1, loss=0.0114]    \n",
      "Epoch 364: 100%|██████████| 34/34 [00:00<00:00, 159.23batch/s, acc=1, loss=0.0113]    \n",
      "Epoch 365: 100%|██████████| 34/34 [00:00<00:00, 242.83batch/s, acc=1, loss=0.0112]    \n",
      "Epoch 366: 100%|██████████| 34/34 [00:00<00:00, 113.81batch/s, acc=1, loss=0.0111]    \n",
      "Epoch 367: 100%|██████████| 34/34 [00:00<00:00, 189.02batch/s, acc=1, loss=0.0111]    \n",
      "Epoch 368: 100%|██████████| 34/34 [00:00<00:00, 266.85batch/s, acc=1, loss=0.011]     \n",
      "Epoch 369: 100%|██████████| 34/34 [00:00<00:00, 255.31batch/s, acc=1, loss=0.0109]    \n",
      "Epoch 370: 100%|██████████| 34/34 [00:00<00:00, 195.17batch/s, acc=1, loss=0.0109]    \n",
      "Epoch 371: 100%|██████████| 34/34 [00:00<00:00, 109.93batch/s, acc=1, loss=0.0108]    \n",
      "Epoch 372: 100%|██████████| 34/34 [00:00<00:00, 181.87batch/s, acc=1, loss=0.0107]    \n",
      "Epoch 373: 100%|██████████| 34/34 [00:00<00:00, 189.46batch/s, acc=1, loss=0.0106]    \n",
      "Epoch 374: 100%|██████████| 34/34 [00:00<00:00, 124.41batch/s, acc=1, loss=0.0106]    \n",
      "Epoch 375: 100%|██████████| 34/34 [00:00<00:00, 70.90batch/s, acc=1, loss=0.0105]     \n",
      "Epoch 376: 100%|██████████| 34/34 [00:00<00:00, 167.79batch/s, acc=1, loss=0.0104]    \n",
      "Epoch 377: 100%|██████████| 34/34 [00:00<00:00, 122.06batch/s, acc=1, loss=0.0104]    \n",
      "Epoch 378: 100%|██████████| 34/34 [00:00<00:00, 149.72batch/s, acc=1, loss=0.0103]    \n",
      "Epoch 379: 100%|██████████| 34/34 [00:00<00:00, 208.18batch/s, acc=1, loss=0.0102]    \n",
      "Epoch 380: 100%|██████████| 34/34 [00:00<00:00, 94.81batch/s, acc=1, loss=0.0102]     \n",
      "Epoch 381: 100%|██████████| 34/34 [00:00<00:00, 191.55batch/s, acc=1, loss=0.0101]    \n",
      "Epoch 382: 100%|██████████| 34/34 [00:00<00:00, 191.25batch/s, acc=1, loss=0.01]      \n",
      "Epoch 383: 100%|██████████| 34/34 [00:00<00:00, 232.51batch/s, acc=1, loss=0.00998]   \n",
      "Epoch 384: 100%|██████████| 34/34 [00:00<00:00, 255.45batch/s, acc=1, loss=0.00991]   \n",
      "Epoch 385: 100%|██████████| 34/34 [00:00<00:00, 100.63batch/s, acc=1, loss=0.00985]  \n",
      "Epoch 386: 100%|██████████| 34/34 [00:00<00:00, 178.75batch/s, acc=1, loss=0.00979]   \n",
      "Epoch 387: 100%|██████████| 34/34 [00:00<00:00, 188.48batch/s, acc=1, loss=0.00973]   \n",
      "Epoch 388: 100%|██████████| 34/34 [00:00<00:00, 128.28batch/s, acc=1, loss=0.00967]   \n",
      "Epoch 389: 100%|██████████| 34/34 [00:00<00:00, 189.93batch/s, acc=1, loss=0.00961]   \n",
      "Epoch 390: 100%|██████████| 34/34 [00:00<00:00, 205.74batch/s, acc=1, loss=0.00955]   \n",
      "Epoch 391: 100%|██████████| 34/34 [00:00<00:00, 261.09batch/s, acc=1, loss=0.00949]   \n",
      "Epoch 392: 100%|██████████| 34/34 [00:00<00:00, 153.75batch/s, acc=1, loss=0.00943]   \n",
      "Epoch 393: 100%|██████████| 34/34 [00:00<00:00, 129.60batch/s, acc=1, loss=0.00937]   \n",
      "Epoch 394: 100%|██████████| 34/34 [00:00<00:00, 216.96batch/s, acc=1, loss=0.00931]   \n",
      "Epoch 395: 100%|██████████| 34/34 [00:00<00:00, 111.60batch/s, acc=1, loss=0.00925]   \n",
      "Epoch 396: 100%|██████████| 34/34 [00:00<00:00, 204.48batch/s, acc=1, loss=0.0092]    \n",
      "Epoch 397: 100%|██████████| 34/34 [00:00<00:00, 268.61batch/s, acc=1, loss=0.00914]   \n",
      "Epoch 398: 100%|██████████| 34/34 [00:00<00:00, 264.64batch/s, acc=1, loss=0.00908]   \n",
      "Epoch 399: 100%|██████████| 34/34 [00:00<00:00, 215.47batch/s, acc=1, loss=0.00903]   \n",
      "Epoch 400: 100%|██████████| 34/34 [00:00<00:00, 115.82batch/s, acc=1, loss=0.00897]   \n",
      "Epoch 401: 100%|██████████| 34/34 [00:00<00:00, 195.10batch/s, acc=1, loss=0.00892]   \n",
      "Epoch 402: 100%|██████████| 34/34 [00:00<00:00, 188.72batch/s, acc=1, loss=0.00886]   \n",
      "Epoch 403: 100%|██████████| 34/34 [00:00<00:00, 248.88batch/s, acc=1, loss=0.00881]   \n",
      "Epoch 404: 100%|██████████| 34/34 [00:00<00:00, 277.98batch/s, acc=1, loss=0.00876]   \n",
      "Epoch 405: 100%|██████████| 34/34 [00:00<00:00, 128.57batch/s, acc=1, loss=0.0087]    \n",
      "Epoch 406: 100%|██████████| 34/34 [00:00<00:00, 201.06batch/s, acc=1, loss=0.00865]   \n",
      "Epoch 407: 100%|██████████| 34/34 [00:00<00:00, 200.12batch/s, acc=1, loss=0.0086]    \n",
      "Epoch 408: 100%|██████████| 34/34 [00:00<00:00, 270.21batch/s, acc=1, loss=0.00855]   \n",
      "Epoch 409: 100%|██████████| 34/34 [00:00<00:00, 223.52batch/s, acc=1, loss=0.0085]    \n",
      "Epoch 410: 100%|██████████| 34/34 [00:00<00:00, 112.46batch/s, acc=1, loss=0.00844]   \n",
      "Epoch 411: 100%|██████████| 34/34 [00:00<00:00, 224.78batch/s, acc=1, loss=0.00839]   \n",
      "Epoch 412: 100%|██████████| 34/34 [00:00<00:00, 117.43batch/s, acc=1, loss=0.00834]   \n",
      "Epoch 413: 100%|██████████| 34/34 [00:00<00:00, 179.65batch/s, acc=1, loss=0.00829]   \n",
      "Epoch 414: 100%|██████████| 34/34 [00:00<00:00, 115.94batch/s, acc=1, loss=0.00825]   \n",
      "Epoch 415: 100%|██████████| 34/34 [00:00<00:00, 207.20batch/s, acc=1, loss=0.0082]    \n",
      "Epoch 416: 100%|██████████| 34/34 [00:00<00:00, 280.92batch/s, acc=1, loss=0.00815]   \n",
      "Epoch 417: 100%|██████████| 34/34 [00:00<00:00, 189.32batch/s, acc=1, loss=0.0081]    \n",
      "Epoch 418: 100%|██████████| 34/34 [00:00<00:00, 119.89batch/s, acc=1, loss=0.00805]   \n",
      "Epoch 419: 100%|██████████| 34/34 [00:00<00:00, 192.50batch/s, acc=1, loss=0.008]     \n",
      "Epoch 420: 100%|██████████| 34/34 [00:00<00:00, 277.96batch/s, acc=1, loss=0.00796]   \n",
      "Epoch 421: 100%|██████████| 34/34 [00:00<00:00, 234.49batch/s, acc=1, loss=0.00791]   \n",
      "Epoch 422: 100%|██████████| 34/34 [00:00<00:00, 272.72batch/s, acc=1, loss=0.00787]   \n",
      "Epoch 423: 100%|██████████| 34/34 [00:00<00:00, 113.65batch/s, acc=1, loss=0.00782]   \n",
      "Epoch 424: 100%|██████████| 34/34 [00:00<00:00, 225.91batch/s, acc=1, loss=0.00777]   \n",
      "Epoch 425: 100%|██████████| 34/34 [00:00<00:00, 241.19batch/s, acc=1, loss=0.00773]   \n",
      "Epoch 426: 100%|██████████| 34/34 [00:00<00:00, 211.98batch/s, acc=1, loss=0.00768]   \n",
      "Epoch 427: 100%|██████████| 34/34 [00:00<00:00, 264.75batch/s, acc=1, loss=0.00764]   \n",
      "Epoch 428: 100%|██████████| 34/34 [00:00<00:00, 117.08batch/s, acc=1, loss=0.0076]    \n",
      "Epoch 429: 100%|██████████| 34/34 [00:00<00:00, 108.86batch/s, acc=1, loss=0.00755]   \n",
      "Epoch 430: 100%|██████████| 34/34 [00:00<00:00, 189.21batch/s, acc=1, loss=0.00751]   \n",
      "Epoch 431: 100%|██████████| 34/34 [00:00<00:00, 137.78batch/s, acc=1, loss=0.00747]   \n",
      "Epoch 432: 100%|██████████| 34/34 [00:00<00:00, 162.17batch/s, acc=1, loss=0.00742]   \n",
      "Epoch 433: 100%|██████████| 34/34 [00:00<00:00, 134.13batch/s, acc=1, loss=0.00738]  \n",
      "Epoch 434: 100%|██████████| 34/34 [00:00<00:00, 157.73batch/s, acc=1, loss=0.00734]   \n",
      "Epoch 435: 100%|██████████| 34/34 [00:00<00:00, 260.66batch/s, acc=1, loss=0.0073]    \n",
      "Epoch 436: 100%|██████████| 34/34 [00:00<00:00, 207.69batch/s, acc=1, loss=0.00726]   \n",
      "Epoch 437: 100%|██████████| 34/34 [00:00<00:00, 147.82batch/s, acc=1, loss=0.00722]   \n",
      "Epoch 438: 100%|██████████| 34/34 [00:00<00:00, 179.24batch/s, acc=1, loss=0.00717]   \n",
      "Epoch 439: 100%|██████████| 34/34 [00:00<00:00, 206.61batch/s, acc=1, loss=0.00713]   \n",
      "Epoch 440: 100%|██████████| 34/34 [00:00<00:00, 128.82batch/s, acc=1, loss=0.00709]   \n",
      "Epoch 441: 100%|██████████| 34/34 [00:00<00:00, 191.45batch/s, acc=1, loss=0.00705]   \n",
      "Epoch 442: 100%|██████████| 34/34 [00:00<00:00, 197.22batch/s, acc=1, loss=0.00702]   \n",
      "Epoch 443: 100%|██████████| 34/34 [00:00<00:00, 148.56batch/s, acc=1, loss=0.00698]   \n",
      "Epoch 444: 100%|██████████| 34/34 [00:00<00:00, 147.51batch/s, acc=1, loss=0.00694]   \n",
      "Epoch 445: 100%|██████████| 34/34 [00:00<00:00, 108.02batch/s, acc=1, loss=0.0069]    \n",
      "Epoch 446: 100%|██████████| 34/34 [00:00<00:00, 212.96batch/s, acc=1, loss=0.00686]   \n",
      "Epoch 447: 100%|██████████| 34/34 [00:00<00:00, 207.69batch/s, acc=1, loss=0.00682]   \n",
      "Epoch 448: 100%|██████████| 34/34 [00:00<00:00, 98.01batch/s, acc=1, loss=0.00678]    \n",
      "Epoch 449: 100%|██████████| 34/34 [00:00<00:00, 188.84batch/s, acc=1, loss=0.00675]   \n",
      "Epoch 450: 100%|██████████| 34/34 [00:00<00:00, 195.27batch/s, acc=1, loss=0.00671]   \n",
      "Epoch 451: 100%|██████████| 34/34 [00:00<00:00, 148.47batch/s, acc=1, loss=0.00667]   \n",
      "Epoch 452: 100%|██████████| 34/34 [00:00<00:00, 148.06batch/s, acc=1, loss=0.00664]   \n",
      "Epoch 453: 100%|██████████| 34/34 [00:00<00:00, 165.10batch/s, acc=1, loss=0.0066]    \n",
      "Epoch 454: 100%|██████████| 34/34 [00:00<00:00, 160.74batch/s, acc=1, loss=0.00656]   \n",
      "Epoch 455: 100%|██████████| 34/34 [00:00<00:00, 159.61batch/s, acc=1, loss=0.00653]   \n",
      "Epoch 456: 100%|██████████| 34/34 [00:00<00:00, 272.48batch/s, acc=1, loss=0.00649]   \n",
      "Epoch 457: 100%|██████████| 34/34 [00:00<00:00, 257.29batch/s, acc=1, loss=0.00646]   \n",
      "Epoch 458: 100%|██████████| 34/34 [00:00<00:00, 104.54batch/s, acc=1, loss=0.00642]   \n",
      "Epoch 459: 100%|██████████| 34/34 [00:00<00:00, 220.59batch/s, acc=1, loss=0.00639]   \n",
      "Epoch 460: 100%|██████████| 34/34 [00:00<00:00, 91.69batch/s, acc=1, loss=0.00635]    \n",
      "Epoch 461: 100%|██████████| 34/34 [00:00<00:00, 128.30batch/s, acc=1, loss=0.00632]   \n",
      "Epoch 462: 100%|██████████| 34/34 [00:00<00:00, 187.09batch/s, acc=1, loss=0.00629]   \n",
      "Epoch 463: 100%|██████████| 34/34 [00:00<00:00, 202.71batch/s, acc=1, loss=0.00625]  \n",
      "Epoch 464: 100%|██████████| 34/34 [00:00<00:00, 227.97batch/s, acc=1, loss=0.00622]   \n",
      "Epoch 465: 100%|██████████| 34/34 [00:00<00:00, 203.83batch/s, acc=1, loss=0.00619]   \n",
      "Epoch 466: 100%|██████████| 34/34 [00:00<00:00, 113.31batch/s, acc=1, loss=0.00615]   \n",
      "Epoch 467: 100%|██████████| 34/34 [00:00<00:00, 194.81batch/s, acc=1, loss=0.00612]   \n",
      "Epoch 468: 100%|██████████| 34/34 [00:00<00:00, 124.78batch/s, acc=1, loss=0.00609]   \n",
      "Epoch 469: 100%|██████████| 34/34 [00:00<00:00, 195.52batch/s, acc=1, loss=0.00606]   \n",
      "Epoch 470: 100%|██████████| 34/34 [00:00<00:00, 218.74batch/s, acc=1, loss=0.00602]   \n",
      "Epoch 471: 100%|██████████| 34/34 [00:00<00:00, 276.29batch/s, acc=1, loss=0.00599]   \n",
      "Epoch 472: 100%|██████████| 34/34 [00:00<00:00, 109.99batch/s, acc=1, loss=0.00596]  \n",
      "Epoch 473: 100%|██████████| 34/34 [00:00<00:00, 202.84batch/s, acc=1, loss=0.00593]   \n",
      "Epoch 474: 100%|██████████| 34/34 [00:00<00:00, 234.45batch/s, acc=1, loss=0.0059]    \n",
      "Epoch 475: 100%|██████████| 34/34 [00:00<00:00, 271.74batch/s, acc=1, loss=0.00587]   \n",
      "Epoch 476: 100%|██████████| 34/34 [00:00<00:00, 102.22batch/s, acc=1, loss=0.00584]   \n",
      "Epoch 477: 100%|██████████| 34/34 [00:00<00:00, 223.16batch/s, acc=1, loss=0.00581]   \n",
      "Epoch 478: 100%|██████████| 34/34 [00:00<00:00, 200.85batch/s, acc=1, loss=0.00578]   \n",
      "Epoch 479: 100%|██████████| 34/34 [00:00<00:00, 105.27batch/s, acc=1, loss=0.00575]   \n",
      "Epoch 480: 100%|██████████| 34/34 [00:00<00:00, 251.12batch/s, acc=1, loss=0.00572]   \n",
      "Epoch 481: 100%|██████████| 34/34 [00:00<00:00, 96.77batch/s, acc=1, loss=0.00569]    \n",
      "Epoch 482: 100%|██████████| 34/34 [00:00<00:00, 220.37batch/s, acc=1, loss=0.00566]   \n",
      "Epoch 483: 100%|██████████| 34/34 [00:00<00:00, 109.20batch/s, acc=1, loss=0.00563]   \n",
      "Epoch 484: 100%|██████████| 34/34 [00:00<00:00, 215.99batch/s, acc=1, loss=0.0056]    \n",
      "Epoch 485: 100%|██████████| 34/34 [00:00<00:00, 272.16batch/s, acc=1, loss=0.00557]   \n",
      "Epoch 486: 100%|██████████| 34/34 [00:00<00:00, 221.81batch/s, acc=1, loss=0.00554]   \n",
      "Epoch 487: 100%|██████████| 34/34 [00:00<00:00, 130.16batch/s, acc=1, loss=0.00551]   \n",
      "Epoch 488: 100%|██████████| 34/34 [00:00<00:00, 201.34batch/s, acc=1, loss=0.00549]   \n",
      "Epoch 489: 100%|██████████| 34/34 [00:00<00:00, 100.87batch/s, acc=1, loss=0.00546]   \n",
      "Epoch 490: 100%|██████████| 34/34 [00:00<00:00, 175.91batch/s, acc=1, loss=0.00543]   \n",
      "Epoch 491: 100%|██████████| 34/34 [00:00<00:00, 268.19batch/s, acc=1, loss=0.0054]    \n",
      "Epoch 492: 100%|██████████| 34/34 [00:00<00:00, 103.56batch/s, acc=1, loss=0.00537]   \n",
      "Epoch 493: 100%|██████████| 34/34 [00:00<00:00, 144.43batch/s, acc=1, loss=0.00535]   \n",
      "Epoch 494: 100%|██████████| 34/34 [00:00<00:00, 225.34batch/s, acc=1, loss=0.00532]   \n",
      "Epoch 495: 100%|██████████| 34/34 [00:00<00:00, 209.50batch/s, acc=1, loss=0.00529]   \n",
      "Epoch 496: 100%|██████████| 34/34 [00:00<00:00, 100.60batch/s, acc=1, loss=0.00527]   \n",
      "Epoch 497: 100%|██████████| 34/34 [00:00<00:00, 163.57batch/s, acc=1, loss=0.00524]   \n",
      "Epoch 498: 100%|██████████| 34/34 [00:00<00:00, 208.50batch/s, acc=1, loss=0.00521]   \n",
      "Epoch 499: 100%|██████████| 34/34 [00:00<00:00, 280.31batch/s, acc=1, loss=0.00519]   \n"
     ]
    }
   ],
   "source": [
    "clf = sg_detection.LinearClassifier(input_size=512)\n",
    "acc = train_classifier(clf, feats, stacked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def classifier_performance(clf, X, labels):\n",
    "    y = torch.tensor(labels).float().squeeze()\n",
    "    y_pred = clf(X)\n",
    "    acc = (y_pred.round() == y).float().mean()\n",
    "    print(\"Accuracy: \", acc)\n",
    "    y_pred_np = y_pred.detach().numpy()\n",
    "    c_m = confusion_matrix(labels, y_pred_np.round())\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(c_m)\n",
    "    return acc, c_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.9261)\n",
      "Confusion Matrix: \n",
      "[[1292   15]\n",
      " [   5   42]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.9261),\n",
       " array([[1292,   15],\n",
       "        [   5,   42]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_performance(clf, feats, stacked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 34/34 [00:00<00:00, 218.37batch/s, acc=0.667, loss=0.63] \n",
      "Epoch 1: 100%|██████████| 34/34 [00:00<00:00, 204.51batch/s, acc=0.815, loss=0.522]\n",
      "Epoch 2: 100%|██████████| 34/34 [00:00<00:00, 165.90batch/s, acc=0.852, loss=0.45] \n",
      "Epoch 3: 100%|██████████| 34/34 [00:00<00:00, 219.12batch/s, acc=0.852, loss=0.391]\n",
      "Epoch 4: 100%|██████████| 34/34 [00:00<00:00, 207.78batch/s, acc=0.852, loss=0.343]\n",
      "Epoch 5: 100%|██████████| 34/34 [00:00<00:00, 90.01batch/s, acc=0.852, loss=0.316] \n",
      "Epoch 6: 100%|██████████| 34/34 [00:00<00:00, 152.36batch/s, acc=0.852, loss=0.286]\n",
      "Epoch 7: 100%|██████████| 34/34 [00:00<00:00, 197.59batch/s, acc=0.889, loss=0.266]\n",
      "Epoch 8: 100%|██████████| 34/34 [00:00<00:00, 195.24batch/s, acc=0.889, loss=0.249]\n",
      "Epoch 9: 100%|██████████| 34/34 [00:00<00:00, 271.01batch/s, acc=0.889, loss=0.235]\n",
      "Epoch 10: 100%|██████████| 34/34 [00:00<00:00, 193.96batch/s, acc=0.889, loss=0.22] \n",
      "Epoch 11: 100%|██████████| 34/34 [00:00<00:00, 189.14batch/s, acc=0.926, loss=0.21] \n",
      "Epoch 12: 100%|██████████| 34/34 [00:00<00:00, 176.81batch/s, acc=0.926, loss=0.196]\n",
      "Epoch 13: 100%|██████████| 34/34 [00:00<00:00, 201.43batch/s, acc=0.926, loss=0.188]\n",
      "Epoch 14: 100%|██████████| 34/34 [00:00<00:00, 223.77batch/s, acc=0.926, loss=0.177]\n",
      "Epoch 15: 100%|██████████| 34/34 [00:00<00:00, 211.43batch/s, acc=0.926, loss=0.167]\n",
      "Epoch 16: 100%|██████████| 34/34 [00:00<00:00, 178.99batch/s, acc=0.926, loss=0.159]\n",
      "Epoch 17: 100%|██████████| 34/34 [00:00<00:00, 212.45batch/s, acc=0.926, loss=0.151]\n",
      "Epoch 18: 100%|██████████| 34/34 [00:00<00:00, 211.89batch/s, acc=0.926, loss=0.141]\n",
      "Epoch 19: 100%|██████████| 34/34 [00:00<00:00, 230.77batch/s, acc=0.926, loss=0.135]\n",
      "Epoch 20: 100%|██████████| 34/34 [00:00<00:00, 104.68batch/s, acc=0.963, loss=0.127]\n",
      "Epoch 21: 100%|██████████| 34/34 [00:00<00:00, 292.11batch/s, acc=0.963, loss=0.121]\n",
      "Epoch 22: 100%|██████████| 34/34 [00:00<00:00, 282.66batch/s, acc=0.963, loss=0.114]\n",
      "Epoch 23: 100%|██████████| 34/34 [00:00<00:00, 260.45batch/s, acc=0.963, loss=0.109]\n",
      "Epoch 24: 100%|██████████| 34/34 [00:00<00:00, 272.26batch/s, acc=0.963, loss=0.102]\n",
      "Epoch 25: 100%|██████████| 34/34 [00:00<00:00, 276.65batch/s, acc=0.963, loss=0.0991]\n",
      "Epoch 26: 100%|██████████| 34/34 [00:00<00:00, 276.80batch/s, acc=0.963, loss=0.0914]\n",
      "Epoch 27: 100%|██████████| 34/34 [00:00<00:00, 296.88batch/s, acc=0.963, loss=0.0893]\n",
      "Epoch 28: 100%|██████████| 34/34 [00:00<00:00, 276.61batch/s, acc=0.963, loss=0.083] \n",
      "Epoch 29: 100%|██████████| 34/34 [00:00<00:00, 282.00batch/s, acc=0.963, loss=0.079] \n",
      "Epoch 30: 100%|██████████| 34/34 [00:00<00:00, 274.48batch/s, acc=0.963, loss=0.0754]\n",
      "Epoch 31: 100%|██████████| 34/34 [00:00<00:00, 281.74batch/s, acc=1, loss=0.0714]    \n",
      "Epoch 32: 100%|██████████| 34/34 [00:00<00:00, 274.62batch/s, acc=1, loss=0.0682]    \n",
      "Epoch 33: 100%|██████████| 34/34 [00:00<00:00, 87.43batch/s, acc=1, loss=0.0637]     \n",
      "Epoch 34: 100%|██████████| 34/34 [00:00<00:00, 186.98batch/s, acc=1, loss=0.0611]    \n",
      "Epoch 35: 100%|██████████| 34/34 [00:00<00:00, 196.84batch/s, acc=1, loss=0.0579]    \n",
      "Epoch 36: 100%|██████████| 34/34 [00:00<00:00, 238.07batch/s, acc=1, loss=0.0549]    \n",
      "Epoch 37: 100%|██████████| 34/34 [00:00<00:00, 250.49batch/s, acc=1, loss=0.0528]    \n",
      "Epoch 38: 100%|██████████| 34/34 [00:00<00:00, 230.75batch/s, acc=1, loss=0.0491]    \n",
      "Epoch 39: 100%|██████████| 34/34 [00:00<00:00, 211.34batch/s, acc=1, loss=0.0475]    \n",
      "Epoch 40: 100%|██████████| 34/34 [00:00<00:00, 218.97batch/s, acc=1, loss=0.0443]    \n",
      "Epoch 41: 100%|██████████| 34/34 [00:00<00:00, 274.01batch/s, acc=1, loss=0.0428]    \n",
      "Epoch 42: 100%|██████████| 34/34 [00:00<00:00, 273.93batch/s, acc=1, loss=0.0402]    \n",
      "Epoch 43: 100%|██████████| 34/34 [00:00<00:00, 262.01batch/s, acc=1, loss=0.0382]    \n",
      "Epoch 44: 100%|██████████| 34/34 [00:00<00:00, 112.84batch/s, acc=1, loss=0.0367]    \n",
      "Epoch 45: 100%|██████████| 34/34 [00:00<00:00, 279.68batch/s, acc=1, loss=0.0348]    \n",
      "Epoch 46: 100%|██████████| 34/34 [00:00<00:00, 281.86batch/s, acc=1, loss=0.0332]    \n",
      "Epoch 47: 100%|██████████| 34/34 [00:00<00:00, 275.36batch/s, acc=1, loss=0.0319]    \n",
      "Epoch 48: 100%|██████████| 34/34 [00:00<00:00, 272.24batch/s, acc=1, loss=0.0294]    \n",
      "Epoch 49: 100%|██████████| 34/34 [00:00<00:00, 271.85batch/s, acc=1, loss=0.029]     \n",
      "Epoch 50: 100%|██████████| 34/34 [00:00<00:00, 186.68batch/s, acc=1, loss=0.0269]    \n",
      "Epoch 51: 100%|██████████| 34/34 [00:00<00:00, 192.02batch/s, acc=1, loss=0.0261]    \n",
      "Epoch 52: 100%|██████████| 34/34 [00:00<00:00, 211.56batch/s, acc=1, loss=0.0246]    \n",
      "Epoch 53: 100%|██████████| 34/34 [00:00<00:00, 90.52batch/s, acc=1, loss=0.0232]     \n",
      "Epoch 54: 100%|██████████| 34/34 [00:00<00:00, 137.14batch/s, acc=1, loss=0.0226]    \n",
      "Epoch 55: 100%|██████████| 34/34 [00:00<00:00, 111.21batch/s, acc=1, loss=0.0211]    \n",
      "Epoch 56: 100%|██████████| 34/34 [00:00<00:00, 117.31batch/s, acc=1, loss=0.0207]    \n",
      "Epoch 57: 100%|██████████| 34/34 [00:00<00:00, 82.75batch/s, acc=1, loss=0.0191]     \n",
      "Epoch 58: 100%|██████████| 34/34 [00:00<00:00, 123.13batch/s, acc=1, loss=0.0188]    \n",
      "Epoch 59: 100%|██████████| 34/34 [00:00<00:00, 164.92batch/s, acc=1, loss=0.0176]    \n",
      "Epoch 60: 100%|██████████| 34/34 [00:00<00:00, 102.36batch/s, acc=1, loss=0.0171]    \n",
      "Epoch 61: 100%|██████████| 34/34 [00:00<00:00, 148.39batch/s, acc=1, loss=0.0162]    \n",
      "Epoch 62: 100%|██████████| 34/34 [00:00<00:00, 205.35batch/s, acc=1, loss=0.0155]    \n",
      "Epoch 63: 100%|██████████| 34/34 [00:00<00:00, 132.77batch/s, acc=1, loss=0.015]     \n",
      "Epoch 64: 100%|██████████| 34/34 [00:00<00:00, 78.36batch/s, acc=1, loss=0.0143]     \n",
      "Epoch 65: 100%|██████████| 34/34 [00:00<00:00, 200.76batch/s, acc=1, loss=0.0135]    \n",
      "Epoch 66: 100%|██████████| 34/34 [00:00<00:00, 188.79batch/s, acc=1, loss=0.0131]    \n",
      "Epoch 67: 100%|██████████| 34/34 [00:00<00:00, 154.60batch/s, acc=1, loss=0.0126]    \n",
      "Epoch 68: 100%|██████████| 34/34 [00:00<00:00, 174.24batch/s, acc=1, loss=0.012]     \n",
      "Epoch 69: 100%|██████████| 34/34 [00:00<00:00, 104.40batch/s, acc=1, loss=0.0116]    \n",
      "Epoch 70: 100%|██████████| 34/34 [00:00<00:00, 151.31batch/s, acc=1, loss=0.011]     \n",
      "Epoch 71: 100%|██████████| 34/34 [00:00<00:00, 88.50batch/s, acc=1, loss=0.0108]     \n",
      "Epoch 72: 100%|██████████| 34/34 [00:00<00:00, 152.30batch/s, acc=1, loss=0.0102]    \n",
      "Epoch 73: 100%|██████████| 34/34 [00:00<00:00, 196.93batch/s, acc=1, loss=0.00983]   \n",
      "Epoch 74: 100%|██████████| 34/34 [00:00<00:00, 213.10batch/s, acc=1, loss=0.00932]   \n",
      "Epoch 75: 100%|██████████| 34/34 [00:00<00:00, 204.84batch/s, acc=1, loss=0.0091]    \n",
      "Epoch 76: 100%|██████████| 34/34 [00:00<00:00, 178.66batch/s, acc=1, loss=0.00883]   \n",
      "Epoch 77: 100%|██████████| 34/34 [00:00<00:00, 92.27batch/s, acc=1, loss=0.00833]    \n",
      "Epoch 78: 100%|██████████| 34/34 [00:00<00:00, 206.16batch/s, acc=1, loss=0.00823]   \n",
      "Epoch 79: 100%|██████████| 34/34 [00:00<00:00, 197.32batch/s, acc=1, loss=0.00777]   \n",
      "Epoch 80: 100%|██████████| 34/34 [00:00<00:00, 210.68batch/s, acc=1, loss=0.00763]   \n",
      "Epoch 81: 100%|██████████| 34/34 [00:00<00:00, 210.21batch/s, acc=1, loss=0.0073]    \n",
      "Epoch 82: 100%|██████████| 34/34 [00:00<00:00, 177.81batch/s, acc=1, loss=0.00702]   \n",
      "Epoch 83: 100%|██████████| 34/34 [00:00<00:00, 80.49batch/s, acc=1, loss=0.00667]    \n",
      "Epoch 84: 100%|██████████| 34/34 [00:00<00:00, 120.27batch/s, acc=1, loss=0.00664]   \n",
      "Epoch 85: 100%|██████████| 34/34 [00:00<00:00, 164.19batch/s, acc=1, loss=0.00633]   \n",
      "Epoch 86: 100%|██████████| 34/34 [00:00<00:00, 197.45batch/s, acc=1, loss=0.00606]   \n",
      "Epoch 87: 100%|██████████| 34/34 [00:00<00:00, 175.45batch/s, acc=1, loss=0.00586]   \n",
      "Epoch 88: 100%|██████████| 34/34 [00:00<00:00, 195.13batch/s, acc=1, loss=0.0057]    \n",
      "Epoch 89: 100%|██████████| 34/34 [00:00<00:00, 78.17batch/s, acc=1, loss=0.00545]    \n",
      "Epoch 90: 100%|██████████| 34/34 [00:00<00:00, 204.56batch/s, acc=1, loss=0.00542]   \n",
      "Epoch 91: 100%|██████████| 34/34 [00:00<00:00, 208.90batch/s, acc=1, loss=0.0051]    \n",
      "Epoch 92: 100%|██████████| 34/34 [00:00<00:00, 204.64batch/s, acc=1, loss=0.00496]   \n",
      "Epoch 93: 100%|██████████| 34/34 [00:00<00:00, 201.91batch/s, acc=1, loss=0.00484]   \n",
      "Epoch 94: 100%|██████████| 34/34 [00:00<00:00, 198.38batch/s, acc=1, loss=0.00467]   \n",
      "Epoch 95: 100%|██████████| 34/34 [00:00<00:00, 87.90batch/s, acc=1, loss=0.00449]    \n",
      "Epoch 96: 100%|██████████| 34/34 [00:00<00:00, 200.78batch/s, acc=1, loss=0.00443]   \n",
      "Epoch 97: 100%|██████████| 34/34 [00:00<00:00, 203.63batch/s, acc=1, loss=0.00422]   \n",
      "Epoch 98: 100%|██████████| 34/34 [00:00<00:00, 201.22batch/s, acc=1, loss=0.00413]   \n",
      "Epoch 99: 100%|██████████| 34/34 [00:00<00:00, 204.10batch/s, acc=1, loss=0.00401]   \n",
      "Epoch 100: 100%|██████████| 34/34 [00:00<00:00, 94.62batch/s, acc=1, loss=0.00391]    \n",
      "Epoch 101: 100%|██████████| 34/34 [00:00<00:00, 213.85batch/s, acc=1, loss=0.00369]   \n",
      "Epoch 102: 100%|██████████| 34/34 [00:00<00:00, 173.47batch/s, acc=1, loss=0.00362]   \n",
      "Epoch 103: 100%|██████████| 34/34 [00:00<00:00, 211.67batch/s, acc=1, loss=0.00347]   \n",
      "Epoch 104: 100%|██████████| 34/34 [00:00<00:00, 207.45batch/s, acc=1, loss=0.00343]   \n",
      "Epoch 105: 100%|██████████| 34/34 [00:00<00:00, 211.64batch/s, acc=1, loss=0.00328]   \n",
      "Epoch 106: 100%|██████████| 34/34 [00:00<00:00, 95.55batch/s, acc=1, loss=0.00326]    \n",
      "Epoch 107: 100%|██████████| 34/34 [00:00<00:00, 216.36batch/s, acc=1, loss=0.00307]   \n",
      "Epoch 108: 100%|██████████| 34/34 [00:00<00:00, 206.72batch/s, acc=1, loss=0.00304]   \n",
      "Epoch 109: 100%|██████████| 34/34 [00:00<00:00, 179.37batch/s, acc=1, loss=0.00287]   \n",
      "Epoch 110: 100%|██████████| 34/34 [00:00<00:00, 197.39batch/s, acc=1, loss=0.00285]   \n",
      "Epoch 111: 100%|██████████| 34/34 [00:00<00:00, 97.27batch/s, acc=1, loss=0.00276]   \n",
      "Epoch 112: 100%|██████████| 34/34 [00:00<00:00, 197.44batch/s, acc=1, loss=0.00268]   \n",
      "Epoch 113: 100%|██████████| 34/34 [00:00<00:00, 212.37batch/s, acc=1, loss=0.00256]   \n",
      "Epoch 114: 100%|██████████| 34/34 [00:00<00:00, 207.72batch/s, acc=1, loss=0.00254]   \n",
      "Epoch 115: 100%|██████████| 34/34 [00:00<00:00, 174.01batch/s, acc=1, loss=0.00242]   \n",
      "Epoch 116: 100%|██████████| 34/34 [00:00<00:00, 94.37batch/s, acc=1, loss=0.00236]    \n",
      "Epoch 117: 100%|██████████| 34/34 [00:00<00:00, 203.75batch/s, acc=1, loss=0.00233]   \n",
      "Epoch 118: 100%|██████████| 34/34 [00:00<00:00, 198.29batch/s, acc=1, loss=0.00223]   \n",
      "Epoch 119: 100%|██████████| 34/34 [00:00<00:00, 205.93batch/s, acc=1, loss=0.0022]    \n",
      "Epoch 120: 100%|██████████| 34/34 [00:00<00:00, 176.77batch/s, acc=1, loss=0.0021]    \n",
      "Epoch 121: 100%|██████████| 34/34 [00:00<00:00, 96.19batch/s, acc=1, loss=0.00207]    \n",
      "Epoch 122: 100%|██████████| 34/34 [00:00<00:00, 194.81batch/s, acc=1, loss=0.002]     \n",
      "Epoch 123: 100%|██████████| 34/34 [00:00<00:00, 198.20batch/s, acc=1, loss=0.00198]   \n",
      "Epoch 124: 100%|██████████| 34/34 [00:00<00:00, 182.04batch/s, acc=1, loss=0.00188]   \n",
      "Epoch 125: 100%|██████████| 34/34 [00:00<00:00, 99.30batch/s, acc=1, loss=0.00188]    \n",
      "Epoch 126: 100%|██████████| 34/34 [00:00<00:00, 211.90batch/s, acc=1, loss=0.00178]   \n",
      "Epoch 127: 100%|██████████| 34/34 [00:00<00:00, 211.45batch/s, acc=1, loss=0.00179]   \n",
      "Epoch 128: 100%|██████████| 34/34 [00:00<00:00, 174.39batch/s, acc=1, loss=0.00175]   \n",
      "Epoch 129: 100%|██████████| 34/34 [00:00<00:00, 205.17batch/s, acc=1, loss=0.00166]   \n",
      "Epoch 130: 100%|██████████| 34/34 [00:00<00:00, 97.12batch/s, acc=1, loss=0.00162]    \n",
      "Epoch 131: 100%|██████████| 34/34 [00:00<00:00, 208.34batch/s, acc=1, loss=0.00157]   \n",
      "Epoch 132: 100%|██████████| 34/34 [00:00<00:00, 206.22batch/s, acc=1, loss=0.00159]   \n",
      "Epoch 133: 100%|██████████| 34/34 [00:00<00:00, 207.68batch/s, acc=1, loss=0.00151]   \n",
      "Epoch 134: 100%|██████████| 34/34 [00:00<00:00, 87.40batch/s, acc=1, loss=0.00148]    \n",
      "Epoch 135: 100%|██████████| 34/34 [00:00<00:00, 189.04batch/s, acc=1, loss=0.00145]   \n",
      "Epoch 136: 100%|██████████| 34/34 [00:00<00:00, 200.48batch/s, acc=1, loss=0.00142]   \n",
      "Epoch 137: 100%|██████████| 34/34 [00:00<00:00, 199.79batch/s, acc=1, loss=0.00134]   \n",
      "Epoch 138: 100%|██████████| 34/34 [00:00<00:00, 95.17batch/s, acc=1, loss=0.00137]    \n",
      "Epoch 139: 100%|██████████| 34/34 [00:00<00:00, 194.92batch/s, acc=1, loss=0.00132]   \n",
      "Epoch 140: 100%|██████████| 34/34 [00:00<00:00, 197.89batch/s, acc=1, loss=0.00127]   \n",
      "Epoch 141: 100%|██████████| 34/34 [00:00<00:00, 126.87batch/s, acc=1, loss=0.00125]   \n",
      "Epoch 142: 100%|██████████| 34/34 [00:00<00:00, 77.36batch/s, acc=1, loss=0.00121]    \n",
      "Epoch 143: 100%|██████████| 34/34 [00:00<00:00, 194.47batch/s, acc=1, loss=0.00119]   \n",
      "Epoch 144: 100%|██████████| 34/34 [00:00<00:00, 160.44batch/s, acc=1, loss=0.00118]   \n",
      "Epoch 145: 100%|██████████| 34/34 [00:00<00:00, 213.93batch/s, acc=1, loss=0.00114]   \n",
      "Epoch 146: 100%|██████████| 34/34 [00:00<00:00, 246.32batch/s, acc=1, loss=0.00111]   \n",
      "Epoch 147: 100%|██████████| 34/34 [00:00<00:00, 114.71batch/s, acc=1, loss=0.00108]   \n",
      "Epoch 148: 100%|██████████| 34/34 [00:00<00:00, 191.35batch/s, acc=1, loss=0.00106]   \n",
      "Epoch 149: 100%|██████████| 34/34 [00:00<00:00, 161.32batch/s, acc=1, loss=0.00105]   \n",
      "Epoch 150: 100%|██████████| 34/34 [00:00<00:00, 261.05batch/s, acc=1, loss=0.00102]   \n",
      "Epoch 151: 100%|██████████| 34/34 [00:00<00:00, 108.60batch/s, acc=1, loss=0.00101]   \n",
      "Epoch 152: 100%|██████████| 34/34 [00:00<00:00, 263.33batch/s, acc=1, loss=0.000963]  \n",
      "Epoch 153: 100%|██████████| 34/34 [00:00<00:00, 273.30batch/s, acc=1, loss=0.000961] \n",
      "Epoch 154: 100%|██████████| 34/34 [00:00<00:00, 118.52batch/s, acc=1, loss=0.00093]   \n",
      "Epoch 155: 100%|██████████| 34/34 [00:00<00:00, 205.07batch/s, acc=1, loss=0.000905]  \n",
      "Epoch 156: 100%|██████████| 34/34 [00:00<00:00, 271.49batch/s, acc=1, loss=0.0009]    \n",
      "Epoch 157: 100%|██████████| 34/34 [00:00<00:00, 272.28batch/s, acc=1, loss=0.000886]  \n",
      "Epoch 158: 100%|██████████| 34/34 [00:00<00:00, 109.15batch/s, acc=1, loss=0.000854]  \n",
      "Epoch 159: 100%|██████████| 34/34 [00:00<00:00, 279.68batch/s, acc=1, loss=0.000845]  \n",
      "Epoch 160: 100%|██████████| 34/34 [00:00<00:00, 275.86batch/s, acc=1, loss=0.000823]  \n",
      "Epoch 161: 100%|██████████| 34/34 [00:00<00:00, 229.33batch/s, acc=1, loss=0.000796] \n",
      "Epoch 162: 100%|██████████| 34/34 [00:00<00:00, 112.74batch/s, acc=1, loss=0.000794]  \n",
      "Epoch 163: 100%|██████████| 34/34 [00:00<00:00, 260.76batch/s, acc=1, loss=0.000777] \n",
      "Epoch 164: 100%|██████████| 34/34 [00:00<00:00, 193.64batch/s, acc=1, loss=0.000765]  \n",
      "Epoch 165: 100%|██████████| 34/34 [00:00<00:00, 95.01batch/s, acc=1, loss=0.000741]   \n",
      "Epoch 166: 100%|██████████| 34/34 [00:00<00:00, 237.95batch/s, acc=1, loss=0.000732]  \n",
      "Epoch 167: 100%|██████████| 34/34 [00:00<00:00, 198.66batch/s, acc=1, loss=0.000724]\n",
      "Epoch 168: 100%|██████████| 34/34 [00:00<00:00, 266.56batch/s, acc=1, loss=0.000705]\n",
      "Epoch 169: 100%|██████████| 34/34 [00:00<00:00, 169.59batch/s, acc=1, loss=0.000676]\n",
      "Epoch 170: 100%|██████████| 34/34 [00:00<00:00, 273.17batch/s, acc=1, loss=0.000669]\n",
      "Epoch 171: 100%|██████████| 34/34 [00:00<00:00, 275.12batch/s, acc=1, loss=0.000652]\n",
      "Epoch 172: 100%|██████████| 34/34 [00:00<00:00, 114.89batch/s, acc=1, loss=0.000641]\n",
      "Epoch 173: 100%|██████████| 34/34 [00:00<00:00, 231.04batch/s, acc=1, loss=0.000636]\n",
      "Epoch 174: 100%|██████████| 34/34 [00:00<00:00, 274.43batch/s, acc=1, loss=0.000618]\n",
      "Epoch 175: 100%|██████████| 34/34 [00:00<00:00, 130.78batch/s, acc=1, loss=0.000598]\n",
      "Epoch 176: 100%|██████████| 34/34 [00:00<00:00, 219.29batch/s, acc=1, loss=0.000598]\n",
      "Epoch 177: 100%|██████████| 34/34 [00:00<00:00, 270.55batch/s, acc=1, loss=0.00059] \n",
      "Epoch 178: 100%|██████████| 34/34 [00:00<00:00, 271.22batch/s, acc=1, loss=0.000573]\n",
      "Epoch 179: 100%|██████████| 34/34 [00:00<00:00, 106.41batch/s, acc=1, loss=0.000547]\n",
      "Epoch 180: 100%|██████████| 34/34 [00:00<00:00, 273.11batch/s, acc=1, loss=0.000558]\n",
      "Epoch 181: 100%|██████████| 34/34 [00:00<00:00, 272.66batch/s, acc=1, loss=0.000541]\n",
      "Epoch 182: 100%|██████████| 34/34 [00:00<00:00, 92.29batch/s, acc=1, loss=0.000524] \n",
      "Epoch 183: 100%|██████████| 34/34 [00:00<00:00, 269.98batch/s, acc=1, loss=0.000523]\n",
      "Epoch 184: 100%|██████████| 34/34 [00:00<00:00, 272.48batch/s, acc=1, loss=0.000508]\n",
      "Epoch 185: 100%|██████████| 34/34 [00:00<00:00, 106.17batch/s, acc=1, loss=0.000497]\n",
      "Epoch 186: 100%|██████████| 34/34 [00:00<00:00, 271.69batch/s, acc=1, loss=0.000489]\n",
      "Epoch 187: 100%|██████████| 34/34 [00:00<00:00, 274.36batch/s, acc=1, loss=0.000473]\n",
      "Epoch 188: 100%|██████████| 34/34 [00:00<00:00, 110.23batch/s, acc=1, loss=0.000469]\n",
      "Epoch 189: 100%|██████████| 34/34 [00:00<00:00, 129.65batch/s, acc=1, loss=0.000457]\n",
      "Epoch 190: 100%|██████████| 34/34 [00:00<00:00, 121.76batch/s, acc=1, loss=0.000449]\n",
      "Epoch 191: 100%|██████████| 34/34 [00:00<00:00, 74.05batch/s, acc=1, loss=0.00043]  \n",
      "Epoch 192: 100%|██████████| 34/34 [00:00<00:00, 152.78batch/s, acc=1, loss=0.000426]\n",
      "Epoch 193: 100%|██████████| 34/34 [00:00<00:00, 146.24batch/s, acc=1, loss=0.000426]\n",
      "Epoch 194: 100%|██████████| 34/34 [00:00<00:00, 90.44batch/s, acc=1, loss=0.000412] \n",
      "Epoch 195: 100%|██████████| 34/34 [00:00<00:00, 188.25batch/s, acc=1, loss=0.00041] \n",
      "Epoch 196: 100%|██████████| 34/34 [00:00<00:00, 200.64batch/s, acc=1, loss=0.000395]\n",
      "Epoch 197: 100%|██████████| 34/34 [00:00<00:00, 94.52batch/s, acc=1, loss=0.000389] \n",
      "Epoch 198: 100%|██████████| 34/34 [00:00<00:00, 167.45batch/s, acc=1, loss=0.000388]\n",
      "Epoch 199: 100%|██████████| 34/34 [00:00<00:00, 211.46batch/s, acc=1, loss=0.000373]\n",
      "Epoch 200: 100%|██████████| 34/34 [00:00<00:00, 121.93batch/s, acc=1, loss=0.000365]\n",
      "Epoch 201: 100%|██████████| 34/34 [00:00<00:00, 130.24batch/s, acc=1, loss=0.000364]\n",
      "Epoch 202: 100%|██████████| 34/34 [00:00<00:00, 198.69batch/s, acc=1, loss=0.000362]\n",
      "Epoch 203: 100%|██████████| 34/34 [00:00<00:00, 166.86batch/s, acc=1, loss=0.000344]\n",
      "Epoch 204: 100%|██████████| 34/34 [00:00<00:00, 91.36batch/s, acc=1, loss=0.000347] \n",
      "Epoch 205: 100%|██████████| 34/34 [00:00<00:00, 194.64batch/s, acc=1, loss=0.000336]\n",
      "Epoch 206: 100%|██████████| 34/34 [00:00<00:00, 195.73batch/s, acc=1, loss=0.000329]\n",
      "Epoch 207: 100%|██████████| 34/34 [00:00<00:00, 85.30batch/s, acc=1, loss=0.000317] \n",
      "Epoch 208: 100%|██████████| 34/34 [00:00<00:00, 202.90batch/s, acc=1, loss=0.00032] \n",
      "Epoch 209: 100%|██████████| 34/34 [00:00<00:00, 193.89batch/s, acc=1, loss=0.000308]\n",
      "Epoch 210: 100%|██████████| 34/34 [00:00<00:00, 93.42batch/s, acc=1, loss=0.000306] \n",
      "Epoch 211: 100%|██████████| 34/34 [00:00<00:00, 165.25batch/s, acc=1, loss=0.000296]\n",
      "Epoch 212: 100%|██████████| 34/34 [00:00<00:00, 196.56batch/s, acc=1, loss=0.000291]\n",
      "Epoch 213: 100%|██████████| 34/34 [00:00<00:00, 95.88batch/s, acc=1, loss=0.000292] \n",
      "Epoch 214: 100%|██████████| 34/34 [00:00<00:00, 196.80batch/s, acc=1, loss=0.000287]\n",
      "Epoch 215: 100%|██████████| 34/34 [00:00<00:00, 174.65batch/s, acc=1, loss=0.000273]\n",
      "Epoch 216: 100%|██████████| 34/34 [00:00<00:00, 97.31batch/s, acc=1, loss=0.000276] \n",
      "Epoch 217: 100%|██████████| 34/34 [00:00<00:00, 200.89batch/s, acc=1, loss=0.000268]\n",
      "Epoch 218: 100%|██████████| 34/34 [00:00<00:00, 90.23batch/s, acc=1, loss=0.000259] \n",
      "Epoch 219: 100%|██████████| 34/34 [00:00<00:00, 200.26batch/s, acc=1, loss=0.000261]\n",
      "Epoch 220: 100%|██████████| 34/34 [00:00<00:00, 171.97batch/s, acc=1, loss=0.000249]\n",
      "Epoch 221: 100%|██████████| 34/34 [00:00<00:00, 93.98batch/s, acc=1, loss=0.000253] \n",
      "Epoch 222: 100%|██████████| 34/34 [00:00<00:00, 206.48batch/s, acc=1, loss=0.000242]\n",
      "Epoch 223: 100%|██████████| 34/34 [00:00<00:00, 205.33batch/s, acc=1, loss=0.00024] \n",
      "Epoch 224: 100%|██████████| 34/34 [00:00<00:00, 89.03batch/s, acc=1, loss=0.000235] \n",
      "Epoch 225: 100%|██████████| 34/34 [00:00<00:00, 198.77batch/s, acc=1, loss=0.000227]\n",
      "Epoch 226: 100%|██████████| 34/34 [00:00<00:00, 199.99batch/s, acc=1, loss=0.000225]\n",
      "Epoch 227: 100%|██████████| 34/34 [00:00<00:00, 93.67batch/s, acc=1, loss=0.000223] \n",
      "Epoch 228: 100%|██████████| 34/34 [00:00<00:00, 177.98batch/s, acc=1, loss=0.000217]\n",
      "Epoch 229: 100%|██████████| 34/34 [00:00<00:00, 204.15batch/s, acc=1, loss=0.000216]\n",
      "Epoch 230: 100%|██████████| 34/34 [00:00<00:00, 93.30batch/s, acc=1, loss=0.000209] \n",
      "Epoch 231: 100%|██████████| 34/34 [00:00<00:00, 180.23batch/s, acc=1, loss=0.000208]\n",
      "Epoch 232: 100%|██████████| 34/34 [00:00<00:00, 160.14batch/s, acc=1, loss=0.0002]  \n",
      "Epoch 233: 100%|██████████| 34/34 [00:00<00:00, 91.56batch/s, acc=1, loss=0.000201] \n",
      "Epoch 234: 100%|██████████| 34/34 [00:00<00:00, 204.41batch/s, acc=1, loss=0.000195]\n",
      "Epoch 235: 100%|██████████| 34/34 [00:00<00:00, 198.63batch/s, acc=1, loss=0.000194]\n",
      "Epoch 236: 100%|██████████| 34/34 [00:00<00:00, 87.28batch/s, acc=1, loss=0.000188] \n",
      "Epoch 237: 100%|██████████| 34/34 [00:00<00:00, 200.75batch/s, acc=1, loss=0.000185]\n",
      "Epoch 238: 100%|██████████| 34/34 [00:00<00:00, 100.46batch/s, acc=1, loss=0.000182]\n",
      "Epoch 239: 100%|██████████| 34/34 [00:00<00:00, 118.75batch/s, acc=1, loss=0.000181]\n",
      "Epoch 240: 100%|██████████| 34/34 [00:00<00:00, 155.45batch/s, acc=1, loss=0.000173]\n",
      "Epoch 241: 100%|██████████| 34/34 [00:00<00:00, 90.68batch/s, acc=1, loss=0.00017]  \n",
      "Epoch 242: 100%|██████████| 34/34 [00:00<00:00, 145.26batch/s, acc=1, loss=0.000168]\n",
      "Epoch 243: 100%|██████████| 34/34 [00:00<00:00, 196.18batch/s, acc=1, loss=0.000167]\n",
      "Epoch 244: 100%|██████████| 34/34 [00:00<00:00, 90.05batch/s, acc=1, loss=0.000164] \n",
      "Epoch 245: 100%|██████████| 34/34 [00:00<00:00, 190.12batch/s, acc=1, loss=0.00016] \n",
      "Epoch 246: 100%|██████████| 34/34 [00:00<00:00, 92.48batch/s, acc=1, loss=0.00016]  \n",
      "Epoch 247: 100%|██████████| 34/34 [00:00<00:00, 159.71batch/s, acc=1, loss=0.000155]\n",
      "Epoch 248: 100%|██████████| 34/34 [00:00<00:00, 192.54batch/s, acc=1, loss=0.000152]\n",
      "Epoch 249: 100%|██████████| 34/34 [00:00<00:00, 85.49batch/s, acc=1, loss=0.00015]  \n",
      "Epoch 250: 100%|██████████| 34/34 [00:00<00:00, 202.37batch/s, acc=1, loss=0.000147]\n",
      "Epoch 251: 100%|██████████| 34/34 [00:00<00:00, 205.78batch/s, acc=1, loss=0.000145]\n",
      "Epoch 252: 100%|██████████| 34/34 [00:00<00:00, 93.16batch/s, acc=1, loss=0.000142] \n",
      "Epoch 253: 100%|██████████| 34/34 [00:00<00:00, 170.48batch/s, acc=1, loss=0.000139]\n",
      "Epoch 254: 100%|██████████| 34/34 [00:00<00:00, 96.82batch/s, acc=1, loss=0.000138] \n",
      "Epoch 255: 100%|██████████| 34/34 [00:00<00:00, 196.88batch/s, acc=1, loss=0.000137]\n",
      "Epoch 256: 100%|██████████| 34/34 [00:00<00:00, 170.59batch/s, acc=1, loss=0.000132]\n",
      "Epoch 257: 100%|██████████| 34/34 [00:00<00:00, 90.05batch/s, acc=1, loss=0.000131] \n",
      "Epoch 258: 100%|██████████| 34/34 [00:00<00:00, 193.58batch/s, acc=1, loss=0.000129]\n",
      "Epoch 259: 100%|██████████| 34/34 [00:00<00:00, 197.21batch/s, acc=1, loss=0.000123]\n",
      "Epoch 260: 100%|██████████| 34/34 [00:00<00:00, 88.50batch/s, acc=1, loss=0.000124] \n",
      "Epoch 261: 100%|██████████| 34/34 [00:00<00:00, 195.82batch/s, acc=1, loss=0.000122]\n",
      "Epoch 262: 100%|██████████| 34/34 [00:00<00:00, 94.29batch/s, acc=1, loss=0.000119] \n",
      "Epoch 263: 100%|██████████| 34/34 [00:00<00:00, 151.14batch/s, acc=1, loss=0.000119]\n",
      "Epoch 264: 100%|██████████| 34/34 [00:00<00:00, 201.80batch/s, acc=1, loss=0.000115]\n",
      "Epoch 265: 100%|██████████| 34/34 [00:00<00:00, 91.21batch/s, acc=1, loss=0.000114] \n",
      "Epoch 266: 100%|██████████| 34/34 [00:00<00:00, 201.28batch/s, acc=1, loss=0.00011] \n",
      "Epoch 267: 100%|██████████| 34/34 [00:00<00:00, 85.68batch/s, acc=1, loss=0.000109] \n",
      "Epoch 268: 100%|██████████| 34/34 [00:00<00:00, 161.54batch/s, acc=1, loss=0.000108]\n",
      "Epoch 269: 100%|██████████| 34/34 [00:00<00:00, 177.00batch/s, acc=1, loss=0.000107]\n",
      "Epoch 270: 100%|██████████| 34/34 [00:00<00:00, 84.53batch/s, acc=1, loss=0.000104] \n",
      "Epoch 271: 100%|██████████| 34/34 [00:00<00:00, 200.61batch/s, acc=1, loss=0.000102]\n",
      "Epoch 272: 100%|██████████| 34/34 [00:00<00:00, 90.63batch/s, acc=1, loss=0.000101] \n",
      "Epoch 273: 100%|██████████| 34/34 [00:00<00:00, 167.64batch/s, acc=1, loss=9.96e-5] \n",
      "Epoch 274: 100%|██████████| 34/34 [00:00<00:00, 202.62batch/s, acc=1, loss=9.54e-5] \n",
      "Epoch 275: 100%|██████████| 34/34 [00:00<00:00, 96.15batch/s, acc=1, loss=9.75e-5]  \n",
      "Epoch 276: 100%|██████████| 34/34 [00:00<00:00, 158.23batch/s, acc=1, loss=9.42e-5] \n",
      "Epoch 277: 100%|██████████| 34/34 [00:00<00:00, 95.11batch/s, acc=1, loss=9.33e-5]  \n",
      "Epoch 278: 100%|██████████| 34/34 [00:00<00:00, 192.05batch/s, acc=1, loss=8.92e-5] \n",
      "Epoch 279: 100%|██████████| 34/34 [00:00<00:00, 171.99batch/s, acc=1, loss=9.04e-5] \n",
      "Epoch 280: 100%|██████████| 34/34 [00:00<00:00, 90.97batch/s, acc=1, loss=8.85e-5]  \n",
      "Epoch 281: 100%|██████████| 34/34 [00:00<00:00, 203.23batch/s, acc=1, loss=8.55e-5] \n",
      "Epoch 282: 100%|██████████| 34/34 [00:00<00:00, 93.79batch/s, acc=1, loss=8.52e-5]  \n",
      "Epoch 283: 100%|██████████| 34/34 [00:00<00:00, 166.07batch/s, acc=1, loss=8.45e-5] \n",
      "Epoch 284: 100%|██████████| 34/34 [00:00<00:00, 102.72batch/s, acc=1, loss=8.19e-5] \n",
      "Epoch 285: 100%|██████████| 34/34 [00:00<00:00, 163.94batch/s, acc=1, loss=8.13e-5] \n",
      "Epoch 286: 100%|██████████| 34/34 [00:00<00:00, 170.76batch/s, acc=1, loss=8.03e-5] \n",
      "Epoch 287: 100%|██████████| 34/34 [00:00<00:00, 91.10batch/s, acc=1, loss=7.91e-5]  \n",
      "Epoch 288: 100%|██████████| 34/34 [00:00<00:00, 196.94batch/s, acc=1, loss=7.66e-5] \n",
      "Epoch 289: 100%|██████████| 34/34 [00:00<00:00, 170.13batch/s, acc=1, loss=7.49e-5] \n",
      "Epoch 290: 100%|██████████| 34/34 [00:00<00:00, 93.86batch/s, acc=1, loss=7.43e-5]  \n",
      "Epoch 291: 100%|██████████| 34/34 [00:00<00:00, 161.90batch/s, acc=1, loss=7.26e-5] \n",
      "Epoch 292: 100%|██████████| 34/34 [00:00<00:00, 188.31batch/s, acc=1, loss=7.34e-5] \n",
      "Epoch 293: 100%|██████████| 34/34 [00:00<00:00, 94.66batch/s, acc=1, loss=7.02e-5]  \n",
      "Epoch 294: 100%|██████████| 34/34 [00:00<00:00, 202.93batch/s, acc=1, loss=6.98e-5] \n",
      "Epoch 295: 100%|██████████| 34/34 [00:00<00:00, 89.80batch/s, acc=1, loss=6.88e-5]  \n",
      "Epoch 296: 100%|██████████| 34/34 [00:00<00:00, 196.92batch/s, acc=1, loss=6.81e-5] \n",
      "Epoch 297: 100%|██████████| 34/34 [00:00<00:00, 105.96batch/s, acc=1, loss=6.51e-5] \n",
      "Epoch 298: 100%|██████████| 34/34 [00:00<00:00, 148.20batch/s, acc=1, loss=6.52e-5] \n",
      "Epoch 299: 100%|██████████| 34/34 [00:00<00:00, 206.41batch/s, acc=1, loss=6.48e-5] \n",
      "Epoch 300: 100%|██████████| 34/34 [00:00<00:00, 70.72batch/s, acc=1, loss=6.22e-5]  \n",
      "Epoch 301: 100%|██████████| 34/34 [00:00<00:00, 142.46batch/s, acc=1, loss=6.23e-5] \n",
      "Epoch 302: 100%|██████████| 34/34 [00:00<00:00, 77.94batch/s, acc=1, loss=6.12e-5]  \n",
      "Epoch 303: 100%|██████████| 34/34 [00:00<00:00, 149.71batch/s, acc=1, loss=6.02e-5] \n",
      "Epoch 304: 100%|██████████| 34/34 [00:00<00:00, 78.18batch/s, acc=1, loss=5.83e-5]  \n",
      "Epoch 305: 100%|██████████| 34/34 [00:00<00:00, 182.45batch/s, acc=1, loss=5.75e-5] \n",
      "Epoch 306: 100%|██████████| 34/34 [00:00<00:00, 89.00batch/s, acc=1, loss=5.67e-5]  \n",
      "Epoch 307: 100%|██████████| 34/34 [00:00<00:00, 190.75batch/s, acc=1, loss=5.54e-5] \n",
      "Epoch 308: 100%|██████████| 34/34 [00:00<00:00, 103.90batch/s, acc=1, loss=5.55e-5] \n",
      "Epoch 309: 100%|██████████| 34/34 [00:00<00:00, 37.77batch/s, acc=1, loss=5.52e-5] \n",
      "Epoch 310: 100%|██████████| 34/34 [00:00<00:00, 64.72batch/s, acc=1, loss=5.33e-5]  \n",
      "Epoch 311: 100%|██████████| 34/34 [00:00<00:00, 79.08batch/s, acc=1, loss=5.3e-5]   \n",
      "Epoch 312: 100%|██████████| 34/34 [00:00<00:00, 194.50batch/s, acc=1, loss=5.07e-5] \n",
      "Epoch 313: 100%|██████████| 34/34 [00:00<00:00, 82.69batch/s, acc=1, loss=5.06e-5]  \n",
      "Epoch 314: 100%|██████████| 34/34 [00:00<00:00, 174.67batch/s, acc=1, loss=4.99e-5] \n",
      "Epoch 315: 100%|██████████| 34/34 [00:00<00:00, 82.84batch/s, acc=1, loss=4.92e-5]  \n",
      "Epoch 316: 100%|██████████| 34/34 [00:00<00:00, 193.48batch/s, acc=1, loss=4.74e-5] \n",
      "Epoch 317: 100%|██████████| 34/34 [00:00<00:00, 95.70batch/s, acc=1, loss=4.77e-5]  \n",
      "Epoch 318: 100%|██████████| 34/34 [00:00<00:00, 170.08batch/s, acc=1, loss=4.65e-5] \n",
      "Epoch 319: 100%|██████████| 34/34 [00:00<00:00, 195.71batch/s, acc=1, loss=4.58e-5] \n",
      "Epoch 320: 100%|██████████| 34/34 [00:00<00:00, 94.29batch/s, acc=1, loss=4.48e-5]  \n",
      "Epoch 321: 100%|██████████| 34/34 [00:00<00:00, 163.97batch/s, acc=1, loss=4.42e-5] \n",
      "Epoch 322: 100%|██████████| 34/34 [00:00<00:00, 92.41batch/s, acc=1, loss=4.43e-5]  \n",
      "Epoch 323: 100%|██████████| 34/34 [00:00<00:00, 198.51batch/s, acc=1, loss=4.28e-5] \n",
      "Epoch 324: 100%|██████████| 34/34 [00:00<00:00, 89.90batch/s, acc=1, loss=4.23e-5]  \n",
      "Epoch 325: 100%|██████████| 34/34 [00:00<00:00, 192.08batch/s, acc=1, loss=4.15e-5] \n",
      "Epoch 326: 100%|██████████| 34/34 [00:00<00:00, 92.24batch/s, acc=1, loss=4.05e-5]  \n",
      "Epoch 327: 100%|██████████| 34/34 [00:00<00:00, 169.35batch/s, acc=1, loss=3.98e-5] \n",
      "Epoch 328: 100%|██████████| 34/34 [00:00<00:00, 190.13batch/s, acc=1, loss=3.93e-5] \n",
      "Epoch 329: 100%|██████████| 34/34 [00:00<00:00, 86.18batch/s, acc=1, loss=3.88e-5]  \n",
      "Epoch 330: 100%|██████████| 34/34 [00:00<00:00, 197.67batch/s, acc=1, loss=3.69e-5] \n",
      "Epoch 331: 100%|██████████| 34/34 [00:00<00:00, 97.96batch/s, acc=1, loss=3.79e-5]  \n",
      "Epoch 332: 100%|██████████| 34/34 [00:00<00:00, 157.39batch/s, acc=1, loss=3.73e-5] \n",
      "Epoch 333: 100%|██████████| 34/34 [00:00<00:00, 99.15batch/s, acc=1, loss=3.59e-5]  \n",
      "Epoch 334: 100%|██████████| 34/34 [00:00<00:00, 186.25batch/s, acc=1, loss=3.58e-5] \n",
      "Epoch 335: 100%|██████████| 34/34 [00:00<00:00, 99.81batch/s, acc=1, loss=3.46e-5]  \n",
      "Epoch 336: 100%|██████████| 34/34 [00:00<00:00, 157.91batch/s, acc=1, loss=3.45e-5] \n",
      "Epoch 337: 100%|██████████| 34/34 [00:00<00:00, 170.99batch/s, acc=1, loss=3.38e-5] \n",
      "Epoch 338: 100%|██████████| 34/34 [00:00<00:00, 91.67batch/s, acc=1, loss=3.33e-5]  \n",
      "Epoch 339: 100%|██████████| 34/34 [00:00<00:00, 200.61batch/s, acc=1, loss=3.3e-5]  \n",
      "Epoch 340: 100%|██████████| 34/34 [00:00<00:00, 170.88batch/s, acc=1, loss=3.16e-5] \n",
      "Epoch 341: 100%|██████████| 34/34 [00:00<00:00, 94.44batch/s, acc=1, loss=3.14e-5]  \n",
      "Epoch 342: 100%|██████████| 34/34 [00:00<00:00, 153.21batch/s, acc=1, loss=3.09e-5] \n",
      "Epoch 343: 100%|██████████| 34/34 [00:00<00:00, 94.22batch/s, acc=1, loss=3.03e-5]  \n",
      "Epoch 344: 100%|██████████| 34/34 [00:00<00:00, 199.04batch/s, acc=1, loss=2.96e-5] \n",
      "Epoch 345: 100%|██████████| 34/34 [00:00<00:00, 84.78batch/s, acc=1, loss=2.96e-5]  \n",
      "Epoch 346: 100%|██████████| 34/34 [00:00<00:00, 192.18batch/s, acc=1, loss=2.87e-5] \n",
      "Epoch 347: 100%|██████████| 34/34 [00:00<00:00, 87.79batch/s, acc=1, loss=2.88e-5]  \n",
      "Epoch 348: 100%|██████████| 34/34 [00:00<00:00, 187.37batch/s, acc=1, loss=2.87e-5] \n",
      "Epoch 349: 100%|██████████| 34/34 [00:00<00:00, 91.97batch/s, acc=1, loss=2.76e-5]  \n",
      "Epoch 350: 100%|██████████| 34/34 [00:00<00:00, 162.95batch/s, acc=1, loss=2.66e-5] \n",
      "Epoch 351: 100%|██████████| 34/34 [00:00<00:00, 91.75batch/s, acc=1, loss=2.64e-5]  \n",
      "Epoch 352: 100%|██████████| 34/34 [00:00<00:00, 99.64batch/s, acc=1, loss=2.66e-5]  \n",
      "Epoch 353: 100%|██████████| 34/34 [00:00<00:00, 143.88batch/s, acc=1, loss=2.58e-5] \n",
      "Epoch 354: 100%|██████████| 34/34 [00:00<00:00, 184.31batch/s, acc=1, loss=2.55e-5] \n",
      "Epoch 355: 100%|██████████| 34/34 [00:00<00:00, 80.29batch/s, acc=1, loss=2.5e-5]   \n",
      "Epoch 356: 100%|██████████| 34/34 [00:00<00:00, 185.49batch/s, acc=1, loss=2.41e-5] \n",
      "Epoch 357: 100%|██████████| 34/34 [00:00<00:00, 161.65batch/s, acc=1, loss=2.43e-5] \n",
      "Epoch 358: 100%|██████████| 34/34 [00:00<00:00, 88.20batch/s, acc=1, loss=2.37e-5]  \n",
      "Epoch 359: 100%|██████████| 34/34 [00:00<00:00, 151.30batch/s, acc=1, loss=2.33e-5] \n",
      "Epoch 360: 100%|██████████| 34/34 [00:00<00:00, 196.44batch/s, acc=1, loss=2.26e-5] \n",
      "Epoch 361: 100%|██████████| 34/34 [00:00<00:00, 97.64batch/s, acc=1, loss=2.28e-5]  \n",
      "Epoch 362: 100%|██████████| 34/34 [00:00<00:00, 164.75batch/s, acc=1, loss=2.18e-5] \n",
      "Epoch 363: 100%|██████████| 34/34 [00:00<00:00, 193.86batch/s, acc=1, loss=2.2e-5]  \n",
      "Epoch 364: 100%|██████████| 34/34 [00:00<00:00, 86.47batch/s, acc=1, loss=2.15e-5]  \n",
      "Epoch 365: 100%|██████████| 34/34 [00:00<00:00, 189.13batch/s, acc=1, loss=2.1e-5]  \n",
      "Epoch 366: 100%|██████████| 34/34 [00:00<00:00, 97.14batch/s, acc=1, loss=2.03e-5]  \n",
      "Epoch 367: 100%|██████████| 34/34 [00:00<00:00, 161.66batch/s, acc=1, loss=2.04e-5] \n",
      "Epoch 368: 100%|██████████| 34/34 [00:00<00:00, 94.58batch/s, acc=1, loss=2.01e-5]  \n",
      "Epoch 369: 100%|██████████| 34/34 [00:00<00:00, 177.45batch/s, acc=1, loss=1.94e-5] \n",
      "Epoch 370: 100%|██████████| 34/34 [00:00<00:00, 93.83batch/s, acc=1, loss=1.91e-5]  \n",
      "Epoch 371: 100%|██████████| 34/34 [00:00<00:00, 172.99batch/s, acc=1, loss=1.93e-5] \n",
      "Epoch 372: 100%|██████████| 34/34 [00:00<00:00, 192.06batch/s, acc=1, loss=1.86e-5] \n",
      "Epoch 373: 100%|██████████| 34/34 [00:00<00:00, 88.10batch/s, acc=1, loss=1.82e-5]  \n",
      "Epoch 374: 100%|██████████| 34/34 [00:00<00:00, 202.54batch/s, acc=1, loss=1.81e-5] \n",
      "Epoch 375: 100%|██████████| 34/34 [00:00<00:00, 93.22batch/s, acc=1, loss=1.78e-5]  \n",
      "Epoch 376: 100%|██████████| 34/34 [00:00<00:00, 170.04batch/s, acc=1, loss=1.72e-5] \n",
      "Epoch 377: 100%|██████████| 34/34 [00:00<00:00, 199.13batch/s, acc=1, loss=1.75e-5] \n",
      "Epoch 378: 100%|██████████| 34/34 [00:00<00:00, 85.90batch/s, acc=1, loss=1.68e-5]  \n",
      "Epoch 379: 100%|██████████| 34/34 [00:00<00:00, 200.29batch/s, acc=1, loss=1.61e-5] \n",
      "Epoch 380: 100%|██████████| 34/34 [00:00<00:00, 91.02batch/s, acc=1, loss=1.64e-5]  \n",
      "Epoch 381: 100%|██████████| 34/34 [00:00<00:00, 194.87batch/s, acc=1, loss=1.61e-5] \n",
      "Epoch 382: 100%|██████████| 34/34 [00:00<00:00, 87.92batch/s, acc=1, loss=1.56e-5]  \n",
      "Epoch 383: 100%|██████████| 34/34 [00:00<00:00, 170.11batch/s, acc=1, loss=1.53e-5] \n",
      "Epoch 384: 100%|██████████| 34/34 [00:00<00:00, 95.39batch/s, acc=1, loss=1.54e-5]  \n",
      "Epoch 385: 100%|██████████| 34/34 [00:00<00:00, 99.63batch/s, acc=1, loss=1.49e-5]  \n",
      "Epoch 386: 100%|██████████| 34/34 [00:00<00:00, 162.01batch/s, acc=1, loss=1.46e-5] \n",
      "Epoch 387: 100%|██████████| 34/34 [00:00<00:00, 94.91batch/s, acc=1, loss=1.45e-5]  \n",
      "Epoch 388: 100%|██████████| 34/34 [00:00<00:00, 155.88batch/s, acc=1, loss=1.44e-5] \n",
      "Epoch 389: 100%|██████████| 34/34 [00:00<00:00, 163.20batch/s, acc=1, loss=1.39e-5] \n",
      "Epoch 390: 100%|██████████| 34/34 [00:00<00:00, 90.40batch/s, acc=1, loss=1.35e-5]  \n",
      "Epoch 391: 100%|██████████| 34/34 [00:00<00:00, 163.50batch/s, acc=1, loss=1.38e-5] \n",
      "Epoch 392: 100%|██████████| 34/34 [00:00<00:00, 188.32batch/s, acc=1, loss=1.34e-5] \n",
      "Epoch 393: 100%|██████████| 34/34 [00:00<00:00, 73.35batch/s, acc=1, loss=1.29e-5]  \n",
      "Epoch 394: 100%|██████████| 34/34 [00:00<00:00, 149.74batch/s, acc=1, loss=1.28e-5] \n",
      "Epoch 395: 100%|██████████| 34/34 [00:00<00:00, 85.32batch/s, acc=1, loss=1.25e-5]  \n",
      "Epoch 396: 100%|██████████| 34/34 [00:00<00:00, 105.62batch/s, acc=1, loss=1.23e-5] \n",
      "Epoch 397: 100%|██████████| 34/34 [00:00<00:00, 164.24batch/s, acc=1, loss=1.22e-5] \n",
      "Epoch 398: 100%|██████████| 34/34 [00:00<00:00, 86.54batch/s, acc=1, loss=1.22e-5]  \n",
      "Epoch 399: 100%|██████████| 34/34 [00:00<00:00, 182.79batch/s, acc=1, loss=1.16e-5] \n",
      "Epoch 400: 100%|██████████| 34/34 [00:00<00:00, 166.91batch/s, acc=1, loss=1.14e-5] \n",
      "Epoch 401: 100%|██████████| 34/34 [00:00<00:00, 94.18batch/s, acc=1, loss=1.14e-5]  \n",
      "Epoch 402: 100%|██████████| 34/34 [00:00<00:00, 158.70batch/s, acc=1, loss=1.11e-5] \n",
      "Epoch 403: 100%|██████████| 34/34 [00:00<00:00, 78.92batch/s, acc=1, loss=1.09e-5]  \n",
      "Epoch 404: 100%|██████████| 34/34 [00:00<00:00, 153.41batch/s, acc=1, loss=1.07e-5] \n",
      "Epoch 405: 100%|██████████| 34/34 [00:00<00:00, 98.64batch/s, acc=1, loss=1.06e-5]  \n",
      "Epoch 406: 100%|██████████| 34/34 [00:00<00:00, 150.52batch/s, acc=1, loss=1.02e-5] \n",
      "Epoch 407: 100%|██████████| 34/34 [00:00<00:00, 96.30batch/s, acc=1, loss=1.05e-5]  \n",
      "Epoch 408: 100%|██████████| 34/34 [00:00<00:00, 106.73batch/s, acc=1, loss=1.01e-5] \n",
      "Epoch 409: 100%|██████████| 34/34 [00:00<00:00, 97.57batch/s, acc=1, loss=9.68e-6]  \n",
      "Epoch 410: 100%|██████████| 34/34 [00:00<00:00, 95.88batch/s, acc=1, loss=9.91e-6]  \n",
      "Epoch 411: 100%|██████████| 34/34 [00:00<00:00, 160.38batch/s, acc=1, loss=9.52e-6] \n",
      "Epoch 412: 100%|██████████| 34/34 [00:00<00:00, 102.27batch/s, acc=1, loss=9.41e-6] \n",
      "Epoch 413: 100%|██████████| 34/34 [00:00<00:00, 146.88batch/s, acc=1, loss=9.14e-6] \n",
      "Epoch 414: 100%|██████████| 34/34 [00:00<00:00, 81.65batch/s, acc=1, loss=8.98e-6]  \n",
      "Epoch 415: 100%|██████████| 34/34 [00:00<00:00, 181.92batch/s, acc=1, loss=8.93e-6] \n",
      "Epoch 416: 100%|██████████| 34/34 [00:00<00:00, 103.18batch/s, acc=1, loss=8.65e-6] \n",
      "Epoch 417: 100%|██████████| 34/34 [00:00<00:00, 145.03batch/s, acc=1, loss=8.67e-6] \n",
      "Epoch 418: 100%|██████████| 34/34 [00:00<00:00, 106.14batch/s, acc=1, loss=8.47e-6] \n",
      "Epoch 419: 100%|██████████| 34/34 [00:00<00:00, 152.34batch/s, acc=1, loss=8.32e-6] \n",
      "Epoch 420: 100%|██████████| 34/34 [00:00<00:00, 89.22batch/s, acc=1, loss=8.05e-6]  \n",
      "Epoch 421: 100%|██████████| 34/34 [00:00<00:00, 139.67batch/s, acc=1, loss=8.14e-6] \n",
      "Epoch 422: 100%|██████████| 34/34 [00:00<00:00, 71.78batch/s, acc=1, loss=7.77e-6]  \n",
      "Epoch 423: 100%|██████████| 34/34 [00:00<00:00, 95.21batch/s, acc=1, loss=7.8e-6]   \n",
      "Epoch 424: 100%|██████████| 34/34 [00:00<00:00, 125.78batch/s, acc=1, loss=7.58e-6] \n",
      "Epoch 425: 100%|██████████| 34/34 [00:00<00:00, 94.68batch/s, acc=1, loss=7.46e-6]  \n",
      "Epoch 426: 100%|██████████| 34/34 [00:00<00:00, 167.43batch/s, acc=1, loss=7.35e-6] \n",
      "Epoch 427: 100%|██████████| 34/34 [00:00<00:00, 93.30batch/s, acc=1, loss=7.29e-6]  \n",
      "Epoch 428: 100%|██████████| 34/34 [00:00<00:00, 89.88batch/s, acc=1, loss=7.17e-6]  \n",
      "Epoch 429: 100%|██████████| 34/34 [00:00<00:00, 181.51batch/s, acc=1, loss=6.93e-6]\n",
      "Epoch 430: 100%|██████████| 34/34 [00:00<00:00, 153.17batch/s, acc=1, loss=6.73e-6] \n",
      "Epoch 431: 100%|██████████| 34/34 [00:00<00:00, 86.50batch/s, acc=1, loss=6.78e-6]  \n",
      "Epoch 432: 100%|██████████| 34/34 [00:00<00:00, 189.36batch/s, acc=1, loss=6.67e-6] \n",
      "Epoch 433: 100%|██████████| 34/34 [00:00<00:00, 193.23batch/s, acc=1, loss=6.5e-6]  \n",
      "Epoch 434: 100%|██████████| 34/34 [00:00<00:00, 120.16batch/s, acc=1, loss=6.29e-6] \n",
      "Epoch 435: 100%|██████████| 34/34 [00:00<00:00, 95.46batch/s, acc=1, loss=6.32e-6]  \n",
      "Epoch 436: 100%|██████████| 34/34 [00:00<00:00, 156.01batch/s, acc=1, loss=6.16e-6] \n",
      "Epoch 437: 100%|██████████| 34/34 [00:00<00:00, 97.64batch/s, acc=1, loss=6.11e-6] \n",
      "Epoch 438: 100%|██████████| 34/34 [00:00<00:00, 160.78batch/s, acc=1, loss=6.02e-6] \n",
      "Epoch 439: 100%|██████████| 34/34 [00:00<00:00, 86.14batch/s, acc=1, loss=5.74e-6] \n",
      "Epoch 440: 100%|██████████| 34/34 [00:00<00:00, 101.25batch/s, acc=1, loss=5.71e-6] \n",
      "Epoch 441: 100%|██████████| 34/34 [00:00<00:00, 162.83batch/s, acc=1, loss=5.73e-6] \n",
      "Epoch 442: 100%|██████████| 34/34 [00:00<00:00, 91.55batch/s, acc=1, loss=5.66e-6] \n",
      "Epoch 443: 100%|██████████| 34/34 [00:00<00:00, 169.55batch/s, acc=1, loss=5.45e-6] \n",
      "Epoch 444: 100%|██████████| 34/34 [00:00<00:00, 92.90batch/s, acc=1, loss=5.32e-6]  \n",
      "Epoch 445: 100%|██████████| 34/34 [00:00<00:00, 166.18batch/s, acc=1, loss=5.28e-6] \n",
      "Epoch 446: 100%|██████████| 34/34 [00:00<00:00, 98.60batch/s, acc=1, loss=5.14e-6]  \n",
      "Epoch 447: 100%|██████████| 34/34 [00:00<00:00, 157.07batch/s, acc=1, loss=5.11e-6] \n",
      "Epoch 448: 100%|██████████| 34/34 [00:00<00:00, 188.04batch/s, acc=1, loss=5.07e-6] \n",
      "Epoch 449: 100%|██████████| 34/34 [00:00<00:00, 163.48batch/s, acc=1, loss=4.9e-6]  \n",
      "Epoch 450: 100%|██████████| 34/34 [00:00<00:00, 95.60batch/s, acc=1, loss=4.78e-6]  \n",
      "Epoch 451: 100%|██████████| 34/34 [00:00<00:00, 177.03batch/s, acc=1, loss=4.77e-6] \n",
      "Epoch 452: 100%|██████████| 34/34 [00:00<00:00, 85.19batch/s, acc=1, loss=4.69e-6] \n",
      "Epoch 453: 100%|██████████| 34/34 [00:00<00:00, 152.28batch/s, acc=1, loss=4.62e-6]\n",
      "Epoch 454: 100%|██████████| 34/34 [00:00<00:00, 90.26batch/s, acc=1, loss=4.44e-6] \n",
      "Epoch 455: 100%|██████████| 34/34 [00:00<00:00, 165.57batch/s, acc=1, loss=4.41e-6]\n",
      "Epoch 456: 100%|██████████| 34/34 [00:00<00:00, 98.09batch/s, acc=1, loss=4.31e-6] \n",
      "Epoch 457: 100%|██████████| 34/34 [00:00<00:00, 159.80batch/s, acc=1, loss=4.33e-6]\n",
      "Epoch 458: 100%|██████████| 34/34 [00:00<00:00, 100.02batch/s, acc=1, loss=4.23e-6]\n",
      "Epoch 459: 100%|██████████| 34/34 [00:00<00:00, 154.97batch/s, acc=1, loss=4.1e-6] \n",
      "Epoch 460: 100%|██████████| 34/34 [00:00<00:00, 194.44batch/s, acc=1, loss=4.03e-6]\n",
      "Epoch 461: 100%|██████████| 34/34 [00:00<00:00, 88.44batch/s, acc=1, loss=4.01e-6] \n",
      "Epoch 462: 100%|██████████| 34/34 [00:00<00:00, 178.39batch/s, acc=1, loss=3.95e-6]\n",
      "Epoch 463: 100%|██████████| 34/34 [00:00<00:00, 89.45batch/s, acc=1, loss=3.8e-6]  \n",
      "Epoch 464: 100%|██████████| 34/34 [00:00<00:00, 186.86batch/s, acc=1, loss=3.78e-6]\n",
      "Epoch 465: 100%|██████████| 34/34 [00:00<00:00, 85.72batch/s, acc=1, loss=3.76e-6] \n",
      "Epoch 466: 100%|██████████| 34/34 [00:00<00:00, 87.64batch/s, acc=1, loss=3.61e-6] \n",
      "Epoch 467: 100%|██████████| 34/34 [00:00<00:00, 174.55batch/s, acc=1, loss=3.66e-6]\n",
      "Epoch 468: 100%|██████████| 34/34 [00:00<00:00, 87.04batch/s, acc=1, loss=3.48e-6] \n",
      "Epoch 469: 100%|██████████| 34/34 [00:00<00:00, 115.06batch/s, acc=1, loss=3.49e-6]\n",
      "Epoch 470: 100%|██████████| 34/34 [00:00<00:00, 78.28batch/s, acc=1, loss=3.44e-6] \n",
      "Epoch 471: 100%|██████████| 34/34 [00:00<00:00, 88.71batch/s, acc=1, loss=3.34e-6] \n",
      "Epoch 472: 100%|██████████| 34/34 [00:00<00:00, 173.70batch/s, acc=1, loss=3.34e-6]\n",
      "Epoch 473: 100%|██████████| 34/34 [00:00<00:00, 82.91batch/s, acc=1, loss=3.2e-6]  \n",
      "Epoch 474: 100%|██████████| 34/34 [00:00<00:00, 174.18batch/s, acc=1, loss=3.19e-6]\n",
      "Epoch 475: 100%|██████████| 34/34 [00:00<00:00, 87.95batch/s, acc=1, loss=3.09e-6] \n",
      "Epoch 476: 100%|██████████| 34/34 [00:00<00:00, 157.20batch/s, acc=1, loss=3.05e-6]\n",
      "Epoch 477: 100%|██████████| 34/34 [00:00<00:00, 96.32batch/s, acc=1, loss=3.04e-6] \n",
      "Epoch 478: 100%|██████████| 34/34 [00:00<00:00, 149.28batch/s, acc=1, loss=2.97e-6]\n",
      "Epoch 479: 100%|██████████| 34/34 [00:00<00:00, 195.08batch/s, acc=1, loss=2.91e-6]\n",
      "Epoch 480: 100%|██████████| 34/34 [00:00<00:00, 92.69batch/s, acc=1, loss=2.83e-6] \n",
      "Epoch 481: 100%|██████████| 34/34 [00:00<00:00, 147.83batch/s, acc=1, loss=2.82e-6]\n",
      "Epoch 482: 100%|██████████| 34/34 [00:00<00:00, 96.01batch/s, acc=1, loss=2.77e-6] \n",
      "Epoch 483: 100%|██████████| 34/34 [00:00<00:00, 158.14batch/s, acc=1, loss=2.73e-6]\n",
      "Epoch 484: 100%|██████████| 34/34 [00:00<00:00, 93.32batch/s, acc=1, loss=2.62e-6] \n",
      "Epoch 485: 100%|██████████| 34/34 [00:00<00:00, 161.65batch/s, acc=1, loss=2.61e-6]\n",
      "Epoch 486: 100%|██████████| 34/34 [00:00<00:00, 97.70batch/s, acc=1, loss=2.55e-6] \n",
      "Epoch 487: 100%|██████████| 34/34 [00:00<00:00, 142.52batch/s, acc=1, loss=2.54e-6]\n",
      "Epoch 488: 100%|██████████| 34/34 [00:00<00:00, 92.26batch/s, acc=1, loss=2.51e-6] \n",
      "Epoch 489: 100%|██████████| 34/34 [00:00<00:00, 178.53batch/s, acc=1, loss=2.45e-6]\n",
      "Epoch 490: 100%|██████████| 34/34 [00:00<00:00, 158.64batch/s, acc=1, loss=2.4e-6] \n",
      "Epoch 491: 100%|██████████| 34/34 [00:00<00:00, 96.30batch/s, acc=1, loss=2.33e-6] \n",
      "Epoch 492: 100%|██████████| 34/34 [00:00<00:00, 161.27batch/s, acc=1, loss=2.33e-6]\n",
      "Epoch 493: 100%|██████████| 34/34 [00:00<00:00, 100.48batch/s, acc=1, loss=2.26e-6]\n",
      "Epoch 494: 100%|██████████| 34/34 [00:00<00:00, 99.39batch/s, acc=1, loss=2.29e-6] \n",
      "Epoch 495: 100%|██████████| 34/34 [00:00<00:00, 141.37batch/s, acc=1, loss=2.17e-6]\n",
      "Epoch 496: 100%|██████████| 34/34 [00:00<00:00, 158.46batch/s, acc=1, loss=2.17e-6]\n",
      "Epoch 497: 100%|██████████| 34/34 [00:00<00:00, 93.89batch/s, acc=1, loss=2.08e-6] \n",
      "Epoch 498: 100%|██████████| 34/34 [00:00<00:00, 171.78batch/s, acc=1, loss=2.12e-6]\n",
      "Epoch 499: 100%|██████████| 34/34 [00:00<00:00, 192.09batch/s, acc=1, loss=2.07e-6]\n"
     ]
    }
   ],
   "source": [
    "clf_nl = sg_detection.NonLinearClassifier(input_size=512, hidden_size=64)\n",
    "acc = train_classifier(clf_nl, feats, stacked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  tensor(0.9330)\n",
      "Confusion Matrix: \n",
      "[[1300    7]\n",
      " [   7   40]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.9330),\n",
       " array([[1300,    7],\n",
       "        [   7,   40]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_performance(clf_nl, feats, stacked_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 84, 84])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10.7101,  0.0000,  3.3007,  0.0000,  0.0000,  4.7056,  6.2294,  0.0000,\n",
       "          0.7875,  0.0000,  6.0332,  9.9827,  7.6485,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  2.3347,  1.9806,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.9752,  0.0000,  0.0000,\n",
       "          5.9296,  0.0000,  0.0000,  0.0000,  0.0000,  3.1411,  1.7217,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  1.5900,  1.1487,  9.6075,  3.9059,  7.3202,\n",
       "          0.0000,  0.0000,  0.0000,  2.1230,  3.4050,  0.0000,  0.0000,  0.0000,\n",
       "          0.6814,  0.0000,  6.6914,  0.0000,  9.6066,  0.1442,  0.0000,  0.5422,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4422,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0876,  2.1760,  0.0000,  5.8867,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  6.0191, 10.1115,  0.0000,  7.9544,  0.0000,  0.0627,\n",
       "          0.0000,  0.0000,  0.1351,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  1.0380,  0.0000,  0.0000,  0.0000,  2.5446,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  6.9066,  0.0000,  0.0000,  0.0000,  1.8484,\n",
       "          5.4561,  0.0000,  5.3564,  0.4315,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          1.5073,  0.0000,  0.0000,  0.0000,  0.6885,  0.0000,  0.0000,  9.3354,\n",
       "          1.6166,  4.3979,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, 14.4381,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  4.1243,  4.4336,  0.0000,  0.0000,  0.0000,  4.7530,\n",
       "          0.7759,  3.1051,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.5904,  4.5724,\n",
       "          0.0000,  0.0000,  0.0000,  0.4008,  0.0000,  0.0000,  0.0000,  0.8025,\n",
       "          0.0000,  0.0000,  0.0000,  0.7971,  0.0000,  5.2470,  0.0000,  0.0000,\n",
       "          0.0000,  6.2203,  4.3638,  0.0000,  0.0000, 16.6238,  1.9317, 10.7999,\n",
       "          0.0000,  0.0000,  0.0000,  5.6898,  0.0000,  0.0000,  2.4310,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  8.7514,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  1.0555,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  4.0960,\n",
       "          0.2728, 10.1866,  0.0000,  0.0000,  0.0000,  0.0000,  1.4416,  0.0000,\n",
       "          0.0000,  0.0000,  9.3666,  1.2385,  7.6923,  0.0000,  0.0000,  3.0200,\n",
       "          0.2226,  0.4372,  0.5767,  0.0000,  0.0000,  0.0769,  0.0000,  0.0000,\n",
       "          2.5784,  0.2082,  0.0000,  0.0000,  0.0000,  0.0000, 11.0890,  0.0000,\n",
       "          0.0000,  4.1757, 10.1671,  0.0000,  0.0000,  6.3420,  4.2631, 12.0617,\n",
       "          0.0000,  0.0000,  0.0000,  3.1490,  0.3281,  0.0000,  0.0000,  3.0881,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          6.7469,  0.0000,  4.0506,  0.0000,  1.9316,  0.0000,  4.3750,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  8.8725,  0.0000, 14.2533,  6.5904,\n",
       "          2.1691,  0.0000,  4.6775,  0.0000,  0.0000,  0.0000, 10.1914,  5.1644,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.1650,  0.0000,  0.0000,\n",
       "          0.0000,  8.0267,  3.1678,  0.5859,  0.0000,  0.0000,  0.5427,  8.2548,\n",
       "          5.5621,  0.0000,  3.9862,  0.0000,  0.0000,  0.0000,  2.5414,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  8.4067,  0.0000,  0.0000,  0.0000,\n",
       "          0.6160,  2.5975,  0.0000,  0.0000,  5.1285,  0.0000,  0.0000,  3.9262,\n",
       "          4.2113,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.9315,  4.8941,\n",
       "          2.2584,  0.0000,  0.0000,  0.0000,  0.0000,  3.1024,  0.0000,  2.4152,\n",
       "          2.3184,  0.4122,  5.9922,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          6.8891,  0.0000,  0.0670,  0.1396,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          2.4390,  0.0000, 10.9242,  0.0000,  0.0000, 10.4135,  1.5106,  4.2510,\n",
       "          5.4502,  0.0000,  0.0000,  0.0000,  5.2429,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, 18.4269,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  2.8026,\n",
       "          2.3588,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.9875,  0.0000,\n",
       "          0.0000,  0.0000,  5.7188,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          9.1043,  0.0000,  0.0000,  1.6431,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  4.2969,  2.7906,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, 10.2302,  0.0000,  7.4432,  0.6271,  0.0000,  0.0000,\n",
       "          0.0000,  0.6429,  0.0000,  4.0411,  0.0000,  0.0000,  7.1182,  0.0000,\n",
       "          0.0000,  7.7650,  0.0000,  0.0000,  0.0000,  2.5939,  0.0000,  0.0000,\n",
       "          0.0000,  4.5379,  0.0000,  0.0000,  0.0000,  0.0000,  6.0067,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  2.7054,  0.0000,  0.0000,  1.5952,\n",
       "          0.0000,  0.0000,  5.3036,  0.0000,  5.0347,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  4.1141,  3.7288,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          9.1414,  0.2521,  0.0000,  0.0000, 11.3141,  0.2482,  0.0000,  0.8405,\n",
       "          1.5439,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = pre_processed_states[0, :, :, :]\n",
    "obs = obs.reshape(1, 4, 84, 84)\n",
    "obs = obs_as_tensor(obs, agent.policy.device)\n",
    "print(obs.shape)\n",
    "agent.policy.extract_features(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feats \u001b[38;5;241m=\u001b[39m \u001b[43mobs_to_feats\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m, in \u001b[0;36mobs_to_feats\u001b[0;34m(model, obss)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obs \u001b[38;5;129;01min\u001b[39;00m obss:\n\u001b[0;32m----> 5\u001b[0m         obs \u001b[38;5;241m=\u001b[39m \u001b[43mpre_process_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;66;03m# print(obs[0].shape)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoubleDQN\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/research/discovery/discovery/experiments/FeatAct_minigrid/helpers.py:88\u001b[0m, in \u001b[0;36mpre_process_obs\u001b[0;34m(obs, model)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obs\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m     85\u001b[0m     obs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(\n\u001b[1;32m     86\u001b[0m         obs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     87\u001b[0m     )  \u001b[38;5;66;03m# add batch dimension if its just one observation\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# bring colour channel to front\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs_as_tensor(obs, model\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/research/discovery/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:655\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_transpose_dispatcher)\n\u001b[1;32m    589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose\u001b[39m(a, axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    590\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m    Returns an array with axes transposed.\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m \n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtranspose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/research/discovery/venv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "feats = obs_to_feats(agent, [state[0, :, :, :]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
