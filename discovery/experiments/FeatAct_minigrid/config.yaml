env_name: 'MiniGrid-DoorKey-5x5-v0'
learner: 'DDQN'
project_name: 'testing_shared_private'
timesteps: 100000
policy_type: 'CnnPolicy'
cnn: 'minigrid' # 'nature', 'minigrid', 'minigrid_sp'
activation: 'relu'
feat_dim: 128
stats_window_size: 10
record_video: False
render_mode: 'rgb_array'

# Shared hypers
lr: 0.0003 # PPO_def: 3e-4
gamma: 0.99 # PPO_def: 0.99
batch_size: 96 # PPO_def: 64, DQN_def: 32

# PPO hypers & SB3 defaults
n_epochs: 4 # 10
n_steps: 128 # 2048
n_envs: 16 # 1 #TODO this affects DDQN too!

# (D)DQN hypers & SB3 defaults
learning_starts: 1000 # 100
train_freq: 1 # 4
exploration_final_eps: 0.1 # 0.05
target_update_interval: 500 # 10000

# Env-specific hypers
random_hallway: True # TwoRoomEnv